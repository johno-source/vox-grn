{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment GRN data using pyAudioAnalysis\n",
    "\n",
    "The group of notebooks SegmentPyVOXn.ipynb (n=0-9) will be used to segment the data using the segmentation algorithm I developed in DevelopASSegmentation.ipynb. It follows the same pattern as used in SegmentFVOXn.ipynb.\n",
    "\n",
    "# Data to be Created\n",
    "\n",
    "Three sets of data will be made, 4, 6, and 10 second data. \n",
    "\n",
    "This file will take a long time to run. For that reason it will check point its progress at regular intervals by writing smaller files. If its progress is restarted for any reason it will use those files to determine where it was up to. Segmenting the data is the slow part. For each audio file a segment file will be generated. If mp3 files are to be generated later using different parameters the segmented files should make the process much quicker.\n",
    "\n",
    "The input to this process is the same as SegmentFVOX.ipynb. We actually use its division of the files into 10 groups.\n",
    "\n",
    "The output will be:\n",
    "    \n",
    "    1. /media/originals/py_audio_seg/[iso]/[filename].pkl\n",
    "        where each pkl file contains the list of raw segments for the item.\n",
    "    2. /media/originals/py_audio_seg/seg_4sec.csv\n",
    "        all the metadata for the seg_4sec dataset. Metadata needed for the dataset can be derived from this.\n",
    "    3. /media/originals/py_audio_seg/seg_6sec.csv\n",
    "        all the metadata for the seg_6sec dataset. Metadata needed for the dataset can be derived from this.\n",
    "    4. /media/originals/py_audio_seg/seg_10sec.csv\n",
    "        all the metadata for the seg_10sec dataset. Metadata needed for the dataset can be derived from this.\n",
    "    5. /media/originals/datasets/py_audio_seg_4sec/data/[iso]/[program_id]_[item_no]_[seg].mp3\n",
    "        which is an mp3 for each segment\n",
    "    6. /media/originals/datasets/py_audio_seg_6sec/data/[iso]/[program_id]_[item_no]_[seg].mp3\n",
    "        which is an mp3 for each segment\n",
    "    7. /media/originals/datasets/py_audio_seg_10sec/data/[iso]/[program_id]_[item_no]_[seg].mp3\n",
    "        which is an mp3 for each segment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle as pkl\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('~/work/pyAudioAnalysis'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from collections import namedtuple\n",
    "from pydub import AudioSegment\n",
    "\n",
    "from pyAudioAnalysis import audioSegmentation as aS\n",
    "from pyAudioAnalysis import audioTrainTest as at\n",
    "from pyAudioAnalysis import MidTermFeatures as mtf\n",
    "from pyAudioAnalysis import audioBasicIO as aIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the locations for each of the file types\n",
    "NOTEBOOK_ID=0\n",
    "SEGMENTS_DIR = '/media/originals/py_audio_seg/'\n",
    "DATASETS_DIR = '/media/originals/datasets/'\n",
    "SEC_4_DATA_DIR = 'py_audio_seg_4sec/data/'\n",
    "SEC_6_DATA_DIR = 'py_audio_seg_6sec/data/'\n",
    "SEC_10_DATA_DIR = 'py_audio_seg_10sec/data/'\n",
    "\n",
    "# define specific files used in the process\n",
    "SEG_4_SEC_DF = f'{SEGMENTS_DIR}seg_4sec_{NOTEBOOK_ID}.csv'\n",
    "SEG_6_SEC_DF = f'{SEGMENTS_DIR}seg_6sec_{NOTEBOOK_ID}.csv'\n",
    "SEG_10_SEC_DF = f'{SEGMENTS_DIR}seg_10sec_{NOTEBOOK_ID}.csv'\n",
    "\n",
    "# define segment sizes for each dataset\n",
    "SEG_4_SEC = 4.0\n",
    "SEG_6_SEC = 6.0\n",
    "SEG_10_SEC = 10.0\n",
    "\n",
    "SAMPLING_RATE = 16000\n",
    "\n",
    "def convert_to_ms(sec):\n",
    "    return int(sec*1000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'iso', 'language_name', 'track', 'location', 'year',\n",
       "       'path', 'filename', 'length', 'program'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now read in the description of the input and remove the unwanted columns and rename the rest to be python attribute names.\n",
    "fd = pd.read_csv(f'/media/originals/fsegs/files_{NOTEBOOK_ID}.csv')\n",
    "fd.set_index('ID', inplace=True)\n",
    "fd.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                                  198133\n",
      "iso                                            aar\n",
      "language_name                                 Afar\n",
      "track                                            5\n",
      "location                                    Asmara\n",
      "year                                        1967.0\n",
      "path             Programs/02/02110/A02110/From_CM/\n",
      "filename                            C02110A-05.wav\n",
      "length                                  176.137625\n",
      "program                                       2110\n",
      "Name: 02110_005, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(fd.iloc[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['14610_001', '14610_002', '13981_002', '13981_001', '64296_012',\n",
      "       '64296_011', '64296_009', '64296_008', '64296_010', '64296_006',\n",
      "       ...\n",
      "       '62996_023', '62996_022', '62996_021', '62996_020', '62996_019',\n",
      "       '62996_018', '62996_017', '62996_016', '62996_015', '62996_014'],\n",
      "      dtype='object', name='ID', length=20837)\n"
     ]
    }
   ],
   "source": [
    "print(fd.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate directories and filenames\n",
    "def prepare_dir(dirname):\n",
    "    if dirname[-1] != '/':\n",
    "        dirname = dirname + '/'\n",
    "    Path(dirname).mkdir(parents=True, exist_ok=True)\n",
    "    return dirname\n",
    "\n",
    "def prepare_raw_seg_dir(fd):\n",
    "    return prepare_dir(SEGMENTS_DIR + fd.iso)\n",
    "\n",
    "def raw_seg_filename(fd):\n",
    "    return f'{fd.filename}.pkl'\n",
    "\n",
    "def prepare_dataset_data_dir(fd, dataset_dir):\n",
    "    return prepare_dir(DATASETS_DIR + dataset_dir + fd.iso)\n",
    "\n",
    "def seg_mp3_filename(fd, seg):\n",
    "    return f'{fd.filename[:-4]}_{seg:03d}.mp3'\n",
    "\n",
    "def get_fname(fd):\n",
    "    path = fd.path\n",
    "    if path[-1] != '/':\n",
    "        path = path + '/'\n",
    "    files = glob.glob('/media/programs/' + path + fd.filename.replace('\\ufffd', '*'))\n",
    "    if len(files) == 1:\n",
    "        return files[0]\n",
    "    return '/media/programs/' + path + fd.filename\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def condition_audio_segment(audio_seg):\n",
    "    if audio_seg.channels != 1:\n",
    "        audio_seg = audio_seg.set_channels(1)\n",
    "\n",
    "    if audio_seg.sample_width != 2:\n",
    "        audio_seg = audio_seg.set_sample_width(2)\n",
    "\n",
    "    if audio_seg.frame_rate != SAMPLING_RATE:\n",
    "        audio_seg = audio_seg.set_frame_rate(SAMPLING_RATE)\n",
    "    return audio_seg\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# sklearn puts out a lot of annoying warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "Segment = namedtuple('Segment', ['start', 'end', 'classification'])\n",
    "\n",
    "# re-implement a simplified version of mid_term_file_classification\n",
    "# it is implemented as a class to allow the model to be cached.\n",
    "class ExtractVoiceSegments():\n",
    "    classifier, mean, std, class_names, mt_win, mid_step, st_win, \\\n",
    "         st_step, compute_beat = at.load_model('/home/jovyan/work/pyAudioAnalysis/pyAudioAnalysis/data/models/svm_rbf_4class')\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def segments_in(self, signal, sampling_rate, offset):\n",
    "        labels = []\n",
    "\n",
    "        # mid-term feature extraction:\n",
    "        mt_feats, _, _ = \\\n",
    "            mtf.mid_feature_extraction(signal, sampling_rate,\n",
    "                                    ExtractVoiceSegments.mt_win * sampling_rate,\n",
    "                                    ExtractVoiceSegments.mid_step * sampling_rate,\n",
    "                                    round(sampling_rate * ExtractVoiceSegments.st_win),\n",
    "                                    round(sampling_rate * ExtractVoiceSegments.st_step))\n",
    "\n",
    "        # for each feature vector (i.e. for each fix-sized segment):\n",
    "        for col_index in range(mt_feats.shape[1]):\n",
    "            # normalize current feature v\n",
    "            feature_vector = (mt_feats[:, col_index] - ExtractVoiceSegments.mean) / ExtractVoiceSegments.std\n",
    "\n",
    "            # classify vector:\n",
    "            label_predicted, _ = \\\n",
    "                at.classifier_wrapper(ExtractVoiceSegments.classifier, 'svm', feature_vector)\n",
    "            labels.append(label_predicted)\n",
    "\n",
    "        segs, classes = aS.labels_to_segments(labels, ExtractVoiceSegments.mid_step)\n",
    "        # there is a bug in labels to segments when there is a single label. In this case it returns a list rather than a list of lists\n",
    "        if len(labels) == 1:\n",
    "            segs = [].append(segs)\n",
    "        return [] if segs is None else [Segment(seg[0]+offset, seg[1]+offset, ExtractVoiceSegments.class_names[int(label)]) for seg, label in zip(segs, classes)]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This function performs mid-term classification of an audio stream.\n",
    "Towards this end, supervised knowledge is used,\n",
    "i.e. a pre-trained classifier.\n",
    "ARGUMENTS:\n",
    "    - input_file:        path of the input WAV/mp3 file\n",
    "RETURNS:\n",
    "    - list of Segments (see above tuple)\n",
    "\"\"\"\n",
    "def extract_voice_segments(input_file, *, __extract_voice_segments=ExtractVoiceSegments()):\n",
    "    segments = []\n",
    "\n",
    "    # load input file\n",
    "    sampling_rate, signal = aIO.read_audio_file(input_file)\n",
    "\n",
    "    # could not read file\n",
    "    if sampling_rate == 0:\n",
    "        return segments\n",
    "\n",
    "    # convert stereo (if) to mono\n",
    "    signal = aIO.stereo_to_mono(signal)\n",
    "\n",
    "    # find the silence segments\n",
    "    non_silent_segments = aS.silence_removal(signal, sampling_rate, 0.02, 0.02, smooth_window=1.0, weight=0.3)\n",
    "\n",
    "    # work through each segment\n",
    "    for seg in non_silent_segments:\n",
    "        start = int(seg[0]*sampling_rate)\n",
    "        stop = int(seg[1]*sampling_rate)\n",
    "        sig = signal[start:stop]\n",
    "\n",
    "        segments.extend(__extract_voice_segments.segments_in(signal[start:stop], sampling_rate, seg[0]))\n",
    "\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch = namedtuple('Epoch', ['start', 'end'])\n",
    "def speech_epochs_from_segments(segments, epoch_length=4.0, silence_tolerance=0.0):\n",
    "    epochs = []\n",
    "    i = 0\n",
    "    silence_this_epoch = silence_tolerance\n",
    "    while i < len(segments):\n",
    "        seg_duration = segments[i].end - segments[i].start\n",
    "        if segments[i].classification != 'speech':\n",
    "            silence_this_epoch = silence_tolerance\n",
    "\n",
    "        elif seg_duration >= epoch_length:\n",
    "            epochs.append(Epoch(segments[i].start, segments[i].start+epoch_length))\n",
    "            silence_this_epoch = silence_tolerance\n",
    "            # process the same segment again with a smaller size\n",
    "            new_start = segments[i].start+epoch_length\n",
    "            new_end = segments[i].end\n",
    "            if new_start < new_end:\n",
    "                segments[i] = Segment(new_start, new_end, segments[i].classification)\n",
    "                continue\n",
    "        else:\n",
    "            if i+1 < len(segments):\n",
    "                if (segments[i].end + silence_this_epoch) >= segments[i+1].start and segments[i+1].classification == 'speech':\n",
    "                    # did we use up any silence tolerence\n",
    "                    if segments[i].end < segments[i+1].start:\n",
    "                        silence_this_epoch -= (segments[i+1].start - segments[i].end)\n",
    "                    segments[i+1] = Segment(segments[i].start, segments[i+1].end, segments[i].classification)\n",
    "                else:\n",
    "                    silence_this_epoch = silence_tolerance\n",
    "\n",
    "        i+=1\n",
    "\n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_the_segment_info(fd, segs):\n",
    "    fname = prepare_raw_seg_dir(fd) + raw_seg_filename(fd)\n",
    "    with open(fname, 'wb') as pklFile:\n",
    "         pkl.dump(segs, pklFile)\n",
    "\n",
    "def read_the_segment_info(fd):\n",
    "    fname = prepare_raw_seg_dir(fd) + raw_seg_filename(fd)\n",
    "    if os.path.exists(fname):\n",
    "        if os.path.getsize(fname) > 0:\n",
    "            with open(fname, 'rb') as pklFile:\n",
    "                return pkl.load(pklFile)\n",
    "    return []\n",
    "    \n",
    "def update_dataframes(seg_df_csv, seg_records):\n",
    "    # now update the dataframes\n",
    "    if len(seg_records) > 0:\n",
    "        if os.path.isfile(seg_df_csv):\n",
    "            seg_sec_df = pd.concat([pd.read_csv(seg_df_csv, index_col='file_name'), pd.DataFrame.from_records(seg_records, index='file_name')])\n",
    "        else:\n",
    "            seg_sec_df = pd.DataFrame.from_records(seg_records, index='file_name')\n",
    "        seg_sec_df.to_csv(seg_df_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_segments_for_file(fd):\n",
    "    fmt = 'wav'\n",
    "    if fd.filename[-4:].lower() == '.mp3' :\n",
    "        fmt = 'mp3'\n",
    "    audio_seg = AudioSegment.from_file(get_fname(fd), format=fmt)\n",
    "\n",
    "    # now condition the segment and extract the raw segments.\n",
    "    audio_seg = condition_audio_segment(audio_seg)\n",
    "    segs = read_the_segment_info(fd)\n",
    "    if len(segs) == 0:\n",
    "        segs = extract_voice_segments(get_fname(fd))\n",
    "        save_the_segment_info(fd, segs)\n",
    "\n",
    "    return audio_seg, segs\n",
    "\n",
    "\n",
    "def create_mp3_files(audio_seg, segs, time_per_segment, dataset_dir, fd):\n",
    "    epochs_for_time = speech_epochs_from_segments(segs, epoch_length=time_per_segment, silence_tolerance=time_per_segment/4.0)\n",
    "\n",
    "    # now write out the 4 sec segments\n",
    "    dirname = prepare_dataset_data_dir(fd, dataset_dir)\n",
    "    rows = list()\n",
    "\n",
    "    for i, seg in enumerate(epochs_for_time):\n",
    "        file_name = dataset_dir + fd.iso + '/' + seg_mp3_filename(fd, i)\n",
    "        fname = dirname + seg_mp3_filename(fd, i)\n",
    "        start = convert_to_ms(seg.start)\n",
    "        stop = convert_to_ms(seg.end)\n",
    "        if not os.path.exists(fname):\n",
    "            audio_seg[start:stop].export(fname, format='mp3', bitrate='32k')\n",
    "        desc = dict(fd._asdict())\n",
    "        desc['seg_start'] = start\n",
    "        desc['seg_stop'] = stop\n",
    "        desc['seg'] = i\n",
    "        desc['file_name'] = file_name\n",
    "        rows.append(desc)\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing these items might take a very long time. To permit the process to be interrupted and restarted the indexes of processed items\n",
    "# are maintained in a set that is pickled on each batch. This allows the batch to quickly pick up where it left off.\n",
    "def process_record_batch(files_df, *, batch_size=10):\n",
    "    batch_proc = 0\n",
    "    processed_file = f'{SEGMENTS_DIR}processed16_{NOTEBOOK_ID}.pkl'\n",
    "    if os.path.isfile(processed_file):\n",
    "        with open(processed_file, 'rb') as pklFile:\n",
    "            processed_files = pkl.load(pklFile)\n",
    "    else:\n",
    "        processed_files = set()\n",
    "\n",
    "    segmented_4sec_segs = []\n",
    "    segmented_6sec_segs = []\n",
    "    segmented_10sec_segs = []\n",
    "\n",
    "    for fd in files_df.itertuples():\n",
    "        if batch_proc < batch_size:\n",
    "            if fd.Index not in processed_files:\n",
    "                try:\n",
    "                    audio_seg, voice_segs = extract_audio_segments_for_file(fd)\n",
    "\n",
    "                    segmented_4sec_segs.extend(create_mp3_files(audio_seg, voice_segs, SEG_4_SEC, SEC_4_DATA_DIR, fd))\n",
    "                    segmented_6sec_segs.extend(create_mp3_files(audio_seg, voice_segs, SEG_6_SEC, SEC_6_DATA_DIR, fd))\n",
    "                    segmented_10sec_segs.extend(create_mp3_files(audio_seg, voice_segs, SEG_10_SEC, SEC_10_DATA_DIR, fd))\n",
    "                except:\n",
    "                    print(f'exception {fd.filename}')\n",
    "                    pass\n",
    "\n",
    "                # we want to add an fd that has an exception so it is not reprocessed on every batch\n",
    "                processed_files.add(fd.Index)\n",
    "                batch_proc += 1\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    update_dataframes(SEG_4_SEC_DF, segmented_4sec_segs)\n",
    "    update_dataframes(SEG_6_SEC_DF, segmented_6sec_segs)\n",
    "    update_dataframes(SEG_10_SEC_DF, segmented_10sec_segs)\n",
    "\n",
    "    with open(processed_file, 'wb') as pklFile:\n",
    "        pkl.dump(processed_files, pklFile)\n",
    "\n",
    "    return processed_files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10200 out of 20837 in 244.5380642414093 seconds\n",
      "Processed 10250 out of 20837 in 554.7094824314117 seconds\n",
      "Processed 10300 out of 20837 in 843.6885366439819 seconds\n",
      "Processed 10350 out of 20837 in 1316.1399338245392 seconds\n",
      "Processed 10400 out of 20837 in 2611.583751678467 seconds\n",
      "Processed 10450 out of 20837 in 4817.058678388596 seconds\n",
      "Processed 10500 out of 20837 in 5384.427086830139 seconds\n",
      "Processed 10550 out of 20837 in 6225.92792057991 seconds\n",
      "Processed 10600 out of 20837 in 6651.140037059784 seconds\n",
      "Processed 10650 out of 20837 in 7175.162533760071 seconds\n",
      "Processed 10700 out of 20837 in 7653.366196155548 seconds\n",
      "Processed 10750 out of 20837 in 8165.177758693695 seconds\n",
      "Processed 10800 out of 20837 in 8960.697965860367 seconds\n",
      "Processed 10850 out of 20837 in 9674.555770635605 seconds\n",
      "Processed 10900 out of 20837 in 10588.50389790535 seconds\n",
      "Processed 10950 out of 20837 in 11082.934023141861 seconds\n",
      "Processed 11000 out of 20837 in 11542.068230628967 seconds\n",
      "Processed 11050 out of 20837 in 12032.0544090271 seconds\n",
      "Processed 11100 out of 20837 in 12756.292068004608 seconds\n",
      "Processed 11150 out of 20837 in 13842.53223323822 seconds\n",
      "Processed 11200 out of 20837 in 14744.200154542923 seconds\n",
      "Processed 11250 out of 20837 in 15504.99973320961 seconds\n",
      "Processed 11300 out of 20837 in 16191.923596858978 seconds\n",
      "Processed 11350 out of 20837 in 16932.68124628067 seconds\n",
      "Processed 11400 out of 20837 in 17830.544180870056 seconds\n",
      "Processed 11450 out of 20837 in 18649.05076122284 seconds\n",
      "Processed 11500 out of 20837 in 19566.451778173447 seconds\n",
      "Processed 11550 out of 20837 in 20381.20469379425 seconds\n",
      "Processed 11600 out of 20837 in 21094.032984256744 seconds\n",
      "Processed 11650 out of 20837 in 21989.324487924576 seconds\n",
      "Processed 11700 out of 20837 in 23555.113077878952 seconds\n",
      "Processed 11750 out of 20837 in 24025.25699019432 seconds\n",
      "Processed 11800 out of 20837 in 24930.266869306564 seconds\n",
      "Processed 11850 out of 20837 in 25355.377075195312 seconds\n",
      "Processed 11900 out of 20837 in 26213.463976621628 seconds\n",
      "Processed 11950 out of 20837 in 27632.552671194077 seconds\n",
      "Processed 12000 out of 20837 in 28222.670553922653 seconds\n",
      "Processed 12050 out of 20837 in 28714.380937814713 seconds\n",
      "Processed 12100 out of 20837 in 30153.591054439545 seconds\n",
      "Processed 12150 out of 20837 in 30702.75175333023 seconds\n",
      "Processed 12200 out of 20837 in 31419.801079034805 seconds\n",
      "Processed 12250 out of 20837 in 32740.836158037186 seconds\n",
      "Processed 12300 out of 20837 in 33586.91551852226 seconds\n",
      "Processed 12350 out of 20837 in 34345.50489401817 seconds\n",
      "Processed 12400 out of 20837 in 35237.47714972496 seconds\n",
      "Processed 12450 out of 20837 in 35784.878675699234 seconds\n",
      "Processed 12500 out of 20837 in 37384.44219493866 seconds\n",
      "Processed 12550 out of 20837 in 39973.25108003616 seconds\n",
      "Processed 12600 out of 20837 in 40313.836166620255 seconds\n",
      "Processed 12650 out of 20837 in 40831.84204745293 seconds\n",
      "Processed 12700 out of 20837 in 41246.401709795 seconds\n",
      "Processed 12750 out of 20837 in 42275.3951151371 seconds\n",
      "Processed 12800 out of 20837 in 43104.4458925724 seconds\n",
      "Processed 12850 out of 20837 in 44647.2930624485 seconds\n",
      "Processed 12900 out of 20837 in 45623.65268588066 seconds\n",
      "Processed 12950 out of 20837 in 46568.43371462822 seconds\n",
      "Processed 13000 out of 20837 in 47381.6093006134 seconds\n",
      "Processed 13050 out of 20837 in 47882.05360817909 seconds\n",
      "Processed 13100 out of 20837 in 48984.6284468174 seconds\n",
      "Processed 13150 out of 20837 in 50724.67533278465 seconds\n",
      "Processed 13200 out of 20837 in 52448.097311258316 seconds\n",
      "Processed 13250 out of 20837 in 54405.44297289848 seconds\n",
      "Processed 13300 out of 20837 in 54888.74419426918 seconds\n",
      "Processed 13350 out of 20837 in 56707.66129112244 seconds\n",
      "Processed 13400 out of 20837 in 57870.6976954937 seconds\n",
      "Processed 13450 out of 20837 in 59160.1071805954 seconds\n",
      "Processed 13500 out of 20837 in 60173.11294865608 seconds\n",
      "Processed 13550 out of 20837 in 61040.05141758919 seconds\n",
      "Processed 13600 out of 20837 in 62551.0423707962 seconds\n",
      "Processed 13650 out of 20837 in 63231.73443865776 seconds\n",
      "Processed 13700 out of 20837 in 64086.59924530983 seconds\n",
      "Processed 13750 out of 20837 in 64694.5107858181 seconds\n",
      "Processed 13800 out of 20837 in 67299.63962769508 seconds\n",
      "Processed 13850 out of 20837 in 68369.61818361282 seconds\n",
      "Processed 13900 out of 20837 in 68996.51871442795 seconds\n",
      "Processed 13950 out of 20837 in 73227.0042514801 seconds\n",
      "Processed 14000 out of 20837 in 76605.0486369133 seconds\n",
      "Processed 14050 out of 20837 in 77309.25448894501 seconds\n",
      "Processed 14100 out of 20837 in 78386.99039649963 seconds\n",
      "Processed 14150 out of 20837 in 79435.84680533409 seconds\n",
      "Processed 14200 out of 20837 in 80178.59657073021 seconds\n",
      "Processed 14250 out of 20837 in 80500.41762804985 seconds\n",
      "Processed 14300 out of 20837 in 80964.0321996212 seconds\n",
      "Processed 14350 out of 20837 in 81461.1792769432 seconds\n",
      "Processed 14400 out of 20837 in 83446.81405210495 seconds\n",
      "Processed 14450 out of 20837 in 84708.19434380531 seconds\n",
      "Processed 14500 out of 20837 in 85205.00115585327 seconds\n",
      "Processed 14550 out of 20837 in 85837.38998675346 seconds\n",
      "Processed 14600 out of 20837 in 86835.47831296921 seconds\n",
      "Processed 14650 out of 20837 in 87642.15957164764 seconds\n",
      "Processed 14700 out of 20837 in 88761.82079386711 seconds\n",
      "Processed 14750 out of 20837 in 89321.49897098541 seconds\n",
      "Processed 14800 out of 20837 in 91256.302485466 seconds\n",
      "Processed 14850 out of 20837 in 91828.18768048286 seconds\n",
      "Processed 14900 out of 20837 in 92515.93118858337 seconds\n",
      "Processed 14950 out of 20837 in 93145.79582166672 seconds\n",
      "Processed 15000 out of 20837 in 93778.07762360573 seconds\n",
      "Processed 15050 out of 20837 in 94468.64728450775 seconds\n",
      "Processed 15100 out of 20837 in 94885.67317390442 seconds\n",
      "Processed 15150 out of 20837 in 95323.3241660595 seconds\n",
      "Processed 15200 out of 20837 in 96088.95113325119 seconds\n",
      "Processed 15250 out of 20837 in 96675.34475636482 seconds\n",
      "Processed 15300 out of 20837 in 97327.40930867195 seconds\n",
      "Processed 15350 out of 20837 in 98413.21826028824 seconds\n",
      "Processed 15400 out of 20837 in 98993.35443711281 seconds\n",
      "Processed 15450 out of 20837 in 99499.85532593727 seconds\n",
      "Processed 15500 out of 20837 in 100035.26351118088 seconds\n",
      "Processed 15550 out of 20837 in 100595.4297337532 seconds\n",
      "Processed 15600 out of 20837 in 101600.53117585182 seconds\n",
      "Processed 15650 out of 20837 in 102346.17595434189 seconds\n",
      "Processed 15700 out of 20837 in 102977.85887217522 seconds\n",
      "Processed 15750 out of 20837 in 103567.77507686615 seconds\n",
      "Processed 15800 out of 20837 in 104087.07607221603 seconds\n",
      "Processed 15850 out of 20837 in 104478.12269163132 seconds\n",
      "Processed 15900 out of 20837 in 105103.32563447952 seconds\n",
      "Processed 15950 out of 20837 in 106141.80774188042 seconds\n",
      "Processed 16000 out of 20837 in 108839.85998010635 seconds\n",
      "Processed 16050 out of 20837 in 109460.85293984413 seconds\n",
      "Processed 16100 out of 20837 in 110111.07327222824 seconds\n",
      "Processed 16150 out of 20837 in 110574.79722762108 seconds\n",
      "Processed 16200 out of 20837 in 111061.243673563 seconds\n",
      "Processed 16250 out of 20837 in 111659.79141426086 seconds\n",
      "Processed 16300 out of 20837 in 112254.27200126648 seconds\n",
      "Processed 16350 out of 20837 in 114251.41596841812 seconds\n",
      "Processed 16400 out of 20837 in 115269.88671588898 seconds\n",
      "Processed 16450 out of 20837 in 116463.59061384201 seconds\n",
      "Processed 16500 out of 20837 in 116995.68369603157 seconds\n",
      "Processed 16550 out of 20837 in 117441.97211265564 seconds\n",
      "Processed 16600 out of 20837 in 118083.1895532608 seconds\n",
      "Processed 16650 out of 20837 in 119171.96778821945 seconds\n",
      "Processed 16700 out of 20837 in 119986.62178778648 seconds\n",
      "Processed 16750 out of 20837 in 121931.24973583221 seconds\n",
      "Processed 16800 out of 20837 in 123006.8148818016 seconds\n",
      "Processed 16850 out of 20837 in 123625.94464349747 seconds\n",
      "Processed 16900 out of 20837 in 124204.572473526 seconds\n",
      "Processed 16950 out of 20837 in 124861.54408192635 seconds\n",
      "Processed 17000 out of 20837 in 126551.08623313904 seconds\n",
      "Processed 17050 out of 20837 in 126996.02908706665 seconds\n",
      "Processed 17100 out of 20837 in 127633.00701522827 seconds\n",
      "Processed 17150 out of 20837 in 128958.08662843704 seconds\n",
      "Processed 17200 out of 20837 in 129909.60940885544 seconds\n",
      "Processed 17250 out of 20837 in 131556.83806419373 seconds\n",
      "Processed 17300 out of 20837 in 134991.58082175255 seconds\n",
      "Processed 17350 out of 20837 in 135759.40903306007 seconds\n",
      "Processed 17400 out of 20837 in 136292.92436408997 seconds\n",
      "Processed 17450 out of 20837 in 137795.7457256317 seconds\n",
      "Processed 17500 out of 20837 in 138558.91320633888 seconds\n",
      "Processed 17550 out of 20837 in 139718.48525166512 seconds\n",
      "Processed 17600 out of 20837 in 140914.5213177204 seconds\n",
      "Processed 17650 out of 20837 in 141229.77995610237 seconds\n",
      "Processed 17700 out of 20837 in 142089.9010269642 seconds\n",
      "Processed 17750 out of 20837 in 143051.22546362877 seconds\n",
      "Processed 17800 out of 20837 in 143503.44298887253 seconds\n",
      "Processed 17850 out of 20837 in 144320.81039118767 seconds\n",
      "exception C35511A Region 00_00_00_000 to 00_22_07_492 (01 _ 02).wav\n",
      "Processed 17900 out of 20837 in 144990.50592803955 seconds\n",
      "Processed 17950 out of 20837 in 145620.01851081848 seconds\n",
      "Processed 18000 out of 20837 in 146325.06185102463 seconds\n",
      "Processed 18050 out of 20837 in 147002.30020594597 seconds\n",
      "Processed 18100 out of 20837 in 147858.609821558 seconds\n",
      "Processed 18150 out of 20837 in 148378.89731931686 seconds\n",
      "Processed 18200 out of 20837 in 148949.1949903965 seconds\n",
      "Processed 18250 out of 20837 in 149418.50394535065 seconds\n",
      "Processed 18300 out of 20837 in 149923.2710981369 seconds\n",
      "Processed 18350 out of 20837 in 150995.48107743263 seconds\n",
      "Processed 18400 out of 20837 in 151521.9610862732 seconds\n",
      "Processed 18450 out of 20837 in 152096.17478752136 seconds\n",
      "Processed 18500 out of 20837 in 153259.9176249504 seconds\n",
      "Processed 18550 out of 20837 in 153788.69631886482 seconds\n",
      "Processed 18600 out of 20837 in 154386.38913178444 seconds\n",
      "Processed 18650 out of 20837 in 155384.64982652664 seconds\n",
      "Processed 18700 out of 20837 in 156938.30490756035 seconds\n",
      "Processed 18750 out of 20837 in 158466.1132221222 seconds\n",
      "Processed 18800 out of 20837 in 159408.0556857586 seconds\n",
      "Processed 18850 out of 20837 in 160404.3630168438 seconds\n",
      "Processed 18900 out of 20837 in 161928.63469862938 seconds\n",
      "Processed 18950 out of 20837 in 163571.00265812874 seconds\n",
      "Processed 19000 out of 20837 in 165094.36805009842 seconds\n",
      "Processed 19050 out of 20837 in 166040.8411180973 seconds\n",
      "Processed 19100 out of 20837 in 167336.90570354462 seconds\n",
      "Processed 19150 out of 20837 in 168452.80728125572 seconds\n",
      "Processed 19200 out of 20837 in 169228.1826686859 seconds\n",
      "Processed 19250 out of 20837 in 170625.07195186615 seconds\n",
      "Processed 19300 out of 20837 in 171583.07673311234 seconds\n",
      "Processed 19350 out of 20837 in 172734.25462174416 seconds\n",
      "Processed 19400 out of 20837 in 173265.66299390793 seconds\n",
      "Processed 19450 out of 20837 in 173760.5865843296 seconds\n",
      "Processed 19500 out of 20837 in 174496.36593437195 seconds\n",
      "Processed 19550 out of 20837 in 175153.49055194855 seconds\n",
      "Processed 19600 out of 20837 in 175704.88410449028 seconds\n",
      "Processed 19650 out of 20837 in 176444.64467334747 seconds\n",
      "Processed 19700 out of 20837 in 176957.80160284042 seconds\n",
      "Processed 19750 out of 20837 in 178254.67414593697 seconds\n",
      "Processed 19800 out of 20837 in 179631.66911888123 seconds\n",
      "Processed 19850 out of 20837 in 180041.8714530468 seconds\n",
      "Processed 19900 out of 20837 in 180322.07196331024 seconds\n",
      "Processed 19950 out of 20837 in 180705.6395430565 seconds\n",
      "Processed 20000 out of 20837 in 181335.0076134205 seconds\n",
      "Processed 20050 out of 20837 in 183105.50417637825 seconds\n",
      "Processed 20100 out of 20837 in 184386.18110394478 seconds\n",
      "Processed 20150 out of 20837 in 184914.02053880692 seconds\n",
      "Processed 20200 out of 20837 in 185403.94964003563 seconds\n",
      "Processed 20250 out of 20837 in 185860.5280635357 seconds\n",
      "Processed 20300 out of 20837 in 186444.92992067337 seconds\n",
      "Processed 20350 out of 20837 in 187408.3503537178 seconds\n",
      "Processed 20400 out of 20837 in 187885.91909718513 seconds\n",
      "Processed 20450 out of 20837 in 188241.38665819168 seconds\n",
      "Processed 20500 out of 20837 in 189416.42149281502 seconds\n",
      "Processed 20550 out of 20837 in 191041.00341534615 seconds\n",
      "Processed 20600 out of 20837 in 191511.8991174698 seconds\n",
      "Processed 20650 out of 20837 in 191949.1315612793 seconds\n",
      "Processed 20700 out of 20837 in 192376.52001214027 seconds\n",
      "Processed 20750 out of 20837 in 192858.96524095535 seconds\n",
      "Processed 20800 out of 20837 in 195157.2593357563 seconds\n",
      "Processed 20837 out of 20837 in 195751.45669174194 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# form the language classification file\n",
    "files_processed = 0\n",
    "files_to_process = len(fd)\n",
    "while files_to_process > files_processed:\n",
    "    processed_files = process_record_batch(fd, batch_size=50)\n",
    "    files_processed = len(processed_files)\n",
    "    print(f'Processed {files_processed} out of {files_to_process} in {time.time()-start_time} seconds')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyAudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2abc5501ad3d8eff2da7865cf45fd15699605a857f48109c31373cdc3963a944"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

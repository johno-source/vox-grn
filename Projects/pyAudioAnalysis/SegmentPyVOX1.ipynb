{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment GRN data using pyAudioAnalysis\n",
    "\n",
    "The group of notebooks SegmentPyVOXn.ipynb (n=0-9) will be used to segment the data using the segmentation algorithm I developed in DevelopASSegmentation.ipynb. It follows the same pattern as used in SegmentFVOXn.ipynb.\n",
    "\n",
    "# Data to be Created\n",
    "\n",
    "Three sets of data will be made, 4, 6, and 10 second data. \n",
    "\n",
    "This file will take a long time to run. For that reason it will check point its progress at regular intervals by writing smaller files. If its progress is restarted for any reason it will use those files to determine where it was up to. Segmenting the data is the slow part. For each audio file a segment file will be generated. If mp3 files are to be generated later using different parameters the segmented files should make the process much quicker.\n",
    "\n",
    "The input to this process is the same as SegmentFVOX.ipynb. We actually use its division of the files into 10 groups.\n",
    "\n",
    "The output will be:\n",
    "    \n",
    "    1. /media/originals/py_audio_seg/[iso]/[filename].pkl\n",
    "        where each pkl file contains the list of raw segments for the item.\n",
    "    2. /media/originals/py_audio_seg/seg_4sec.csv\n",
    "        all the metadata for the seg_4sec dataset. Metadata needed for the dataset can be derived from this.\n",
    "    3. /media/originals/py_audio_seg/seg_6sec.csv\n",
    "        all the metadata for the seg_6sec dataset. Metadata needed for the dataset can be derived from this.\n",
    "    4. /media/originals/py_audio_seg/seg_10sec.csv\n",
    "        all the metadata for the seg_10sec dataset. Metadata needed for the dataset can be derived from this.\n",
    "    5. /media/originals/datasets/py_audio_seg_4sec/data/[iso]/[program_id]_[item_no]_[seg].mp3\n",
    "        which is an mp3 for each segment\n",
    "    6. /media/originals/datasets/py_audio_seg_6sec/data/[iso]/[program_id]_[item_no]_[seg].mp3\n",
    "        which is an mp3 for each segment\n",
    "    7. /media/originals/datasets/py_audio_seg_10sec/data/[iso]/[program_id]_[item_no]_[seg].mp3\n",
    "        which is an mp3 for each segment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle as pkl\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('~/work/pyAudioAnalysis'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from collections import namedtuple\n",
    "from pydub import AudioSegment\n",
    "\n",
    "from pyAudioAnalysis import audioSegmentation as aS\n",
    "from pyAudioAnalysis import audioTrainTest as at\n",
    "from pyAudioAnalysis import MidTermFeatures as mtf\n",
    "from pyAudioAnalysis import audioBasicIO as aIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the locations for each of the file types\n",
    "NOTEBOOK_ID=1\n",
    "SEGMENTS_DIR = '/media/originals/py_audio_seg/'\n",
    "DATASETS_DIR = '/media/originals/datasets/'\n",
    "SEC_4_DATA_DIR = 'py_audio_seg_4sec/data/'\n",
    "SEC_6_DATA_DIR = 'py_audio_seg_6sec/data/'\n",
    "SEC_10_DATA_DIR = 'py_audio_seg_10sec/data/'\n",
    "\n",
    "# define specific files used in the process\n",
    "SEG_4_SEC_DF = f'{SEGMENTS_DIR}seg_4sec_{NOTEBOOK_ID}.csv'\n",
    "SEG_6_SEC_DF = f'{SEGMENTS_DIR}seg_6sec_{NOTEBOOK_ID}.csv'\n",
    "SEG_10_SEC_DF = f'{SEGMENTS_DIR}seg_10sec_{NOTEBOOK_ID}.csv'\n",
    "\n",
    "# define segment sizes for each dataset\n",
    "SEG_4_SEC = 4.0\n",
    "SEG_6_SEC = 6.0\n",
    "SEG_10_SEC = 10.0\n",
    "\n",
    "SAMPLING_RATE = 16000\n",
    "\n",
    "def convert_to_ms(sec):\n",
    "    return int(sec*1000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'iso', 'language_name', 'track', 'location', 'year',\n",
       "       'path', 'filename', 'length', 'program'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now read in the description of the input and remove the unwanted columns and rename the rest to be python attribute names.\n",
    "fd = pd.read_csv(f'/media/originals/fsegs/files_{NOTEBOOK_ID}.csv')\n",
    "fd.set_index('ID', inplace=True)\n",
    "fd.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                                   77714\n",
      "iso                                            bjn\n",
      "language_name                         Banjar Malay\n",
      "track                                           28\n",
      "location                     Berau East Kalimantan\n",
      "year                                        2011.0\n",
      "path             Programs/63/63796/A63796/PM-1112/\n",
      "filename                             A63796-28.wav\n",
      "length                                   37.879417\n",
      "program                                      63796\n",
      "Name: 63796_028, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(fd.iloc[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['62996_013', '62996_012', '62996_011', '62996_010', '62996_009',\n",
      "       '63385_018', '63385_017', '63385_016', '63385_015', '63385_014',\n",
      "       ...\n",
      "       '64418_012', '64418_026', '64418_025', '64418_024', '64418_023',\n",
      "       '64418_028', '64418_029', '64418_022', '64418_021', '64418_020'],\n",
      "      dtype='object', name='ID', length=20837)\n"
     ]
    }
   ],
   "source": [
    "print(fd.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate directories and filenames\n",
    "def prepare_dir(dirname):\n",
    "    if dirname[-1] != '/':\n",
    "        dirname = dirname + '/'\n",
    "    Path(dirname).mkdir(parents=True, exist_ok=True)\n",
    "    return dirname\n",
    "\n",
    "def prepare_raw_seg_dir(fd):\n",
    "    return prepare_dir(SEGMENTS_DIR + fd.iso)\n",
    "\n",
    "def raw_seg_filename(fd):\n",
    "    return f'{fd.filename}.pkl'\n",
    "\n",
    "def prepare_dataset_data_dir(fd, dataset_dir):\n",
    "    return prepare_dir(DATASETS_DIR + dataset_dir + fd.iso)\n",
    "\n",
    "def seg_mp3_filename(fd, seg):\n",
    "    return f'{fd.filename[:-4]}_{seg:03d}.mp3'\n",
    "\n",
    "def get_fname(fd):\n",
    "    path = fd.path\n",
    "    if path[-1] != '/':\n",
    "        path = path + '/'\n",
    "    files = glob.glob('/media/programs/' + path + fd.filename.replace('\\ufffd', '*'))\n",
    "    if len(files) == 1:\n",
    "        return files[0]\n",
    "    return '/media/programs/' + path + fd.filename\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def condition_audio_segment(audio_seg):\n",
    "    if audio_seg.channels != 1:\n",
    "        audio_seg = audio_seg.set_channels(1)\n",
    "\n",
    "    if audio_seg.sample_width != 2:\n",
    "        audio_seg = audio_seg.set_sample_width(2)\n",
    "\n",
    "    if audio_seg.frame_rate != SAMPLING_RATE:\n",
    "        audio_seg = audio_seg.set_frame_rate(SAMPLING_RATE)\n",
    "    return audio_seg\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# sklearn puts out a lot of annoying warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "Segment = namedtuple('Segment', ['start', 'end', 'classification'])\n",
    "\n",
    "# re-implement a simplified version of mid_term_file_classification\n",
    "# it is implemented as a class to allow the model to be cached.\n",
    "class ExtractVoiceSegments():\n",
    "    classifier, mean, std, class_names, mt_win, mid_step, st_win, \\\n",
    "         st_step, compute_beat = at.load_model('/home/jovyan/work/pyAudioAnalysis/pyAudioAnalysis/data/models/svm_rbf_4class')\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def segments_in(self, signal, sampling_rate, offset):\n",
    "        labels = []\n",
    "\n",
    "        # mid-term feature extraction:\n",
    "        mt_feats, _, _ = \\\n",
    "            mtf.mid_feature_extraction(signal, sampling_rate,\n",
    "                                    ExtractVoiceSegments.mt_win * sampling_rate,\n",
    "                                    ExtractVoiceSegments.mid_step * sampling_rate,\n",
    "                                    round(sampling_rate * ExtractVoiceSegments.st_win),\n",
    "                                    round(sampling_rate * ExtractVoiceSegments.st_step))\n",
    "\n",
    "        # for each feature vector (i.e. for each fix-sized segment):\n",
    "        for col_index in range(mt_feats.shape[1]):\n",
    "            # normalize current feature v\n",
    "            feature_vector = (mt_feats[:, col_index] - ExtractVoiceSegments.mean) / ExtractVoiceSegments.std\n",
    "\n",
    "            # classify vector:\n",
    "            label_predicted, _ = \\\n",
    "                at.classifier_wrapper(ExtractVoiceSegments.classifier, 'svm', feature_vector)\n",
    "            labels.append(label_predicted)\n",
    "\n",
    "        segs, classes = aS.labels_to_segments(labels, ExtractVoiceSegments.mid_step)\n",
    "        # there is a bug in labels to segments when there is a single label. In this case it returns a list rather than a list of lists\n",
    "        if len(labels) == 1:\n",
    "            segs = [].append(segs)\n",
    "        return [] if segs is None else [Segment(seg[0]+offset, seg[1]+offset, ExtractVoiceSegments.class_names[int(label)]) for seg, label in zip(segs, classes)]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This function performs mid-term classification of an audio stream.\n",
    "Towards this end, supervised knowledge is used,\n",
    "i.e. a pre-trained classifier.\n",
    "ARGUMENTS:\n",
    "    - input_file:        path of the input WAV/mp3 file\n",
    "RETURNS:\n",
    "    - list of Segments (see above tuple)\n",
    "\"\"\"\n",
    "def extract_voice_segments(input_file, *, __extract_voice_segments=ExtractVoiceSegments()):\n",
    "    segments = []\n",
    "\n",
    "    # load input file\n",
    "    sampling_rate, signal = aIO.read_audio_file(input_file)\n",
    "\n",
    "    # could not read file\n",
    "    if sampling_rate == 0:\n",
    "        return segments\n",
    "\n",
    "    # convert stereo (if) to mono\n",
    "    signal = aIO.stereo_to_mono(signal)\n",
    "\n",
    "    # find the silence segments\n",
    "    non_silent_segments = aS.silence_removal(signal, sampling_rate, 0.02, 0.02, smooth_window=1.0, weight=0.3)\n",
    "\n",
    "    # work through each segment\n",
    "    for seg in non_silent_segments:\n",
    "        start = int(seg[0]*sampling_rate)\n",
    "        stop = int(seg[1]*sampling_rate)\n",
    "        sig = signal[start:stop]\n",
    "\n",
    "        segments.extend(__extract_voice_segments.segments_in(signal[start:stop], sampling_rate, seg[0]))\n",
    "\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch = namedtuple('Epoch', ['start', 'end'])\n",
    "def speech_epochs_from_segments(segments, epoch_length=4.0, silence_tolerance=0.0):\n",
    "    epochs = []\n",
    "    i = 0\n",
    "    silence_this_epoch = silence_tolerance\n",
    "    while i < len(segments):\n",
    "        seg_duration = segments[i].end - segments[i].start\n",
    "        if segments[i].classification != 'speech':\n",
    "            silence_this_epoch = silence_tolerance\n",
    "\n",
    "        elif seg_duration >= epoch_length:\n",
    "            epochs.append(Epoch(segments[i].start, segments[i].start+epoch_length))\n",
    "            silence_this_epoch = silence_tolerance\n",
    "            # process the same segment again with a smaller size\n",
    "            new_start = segments[i].start+epoch_length\n",
    "            new_end = segments[i].end\n",
    "            if new_start < new_end:\n",
    "                segments[i] = Segment(new_start, new_end, segments[i].classification)\n",
    "                continue\n",
    "        else:\n",
    "            if i+1 < len(segments):\n",
    "                if (segments[i].end + silence_this_epoch) >= segments[i+1].start and segments[i+1].classification == 'speech':\n",
    "                    # did we use up any silence tolerence\n",
    "                    if segments[i].end < segments[i+1].start:\n",
    "                        silence_this_epoch -= (segments[i+1].start - segments[i].end)\n",
    "                    segments[i+1] = Segment(segments[i].start, segments[i+1].end, segments[i].classification)\n",
    "                else:\n",
    "                    silence_this_epoch = silence_tolerance\n",
    "\n",
    "        i+=1\n",
    "\n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_the_segment_info(fd, segs):\n",
    "    fname = prepare_raw_seg_dir(fd) + raw_seg_filename(fd)\n",
    "    with open(fname, 'wb') as pklFile:\n",
    "         pkl.dump(segs, pklFile)\n",
    "\n",
    "def read_the_segment_info(fd):\n",
    "    fname = prepare_raw_seg_dir(fd) + raw_seg_filename(fd)\n",
    "    if os.path.exists(fname):\n",
    "        if os.path.getsize(fname) > 0:\n",
    "            with open(fname, 'rb') as pklFile:\n",
    "                return pkl.load(pklFile)\n",
    "    return []\n",
    "    \n",
    "def update_dataframes(seg_df_csv, seg_records):\n",
    "    # now update the dataframes\n",
    "    if len(seg_records) > 0:\n",
    "        if os.path.isfile(seg_df_csv):\n",
    "            seg_sec_df = pd.concat([pd.read_csv(seg_df_csv, index_col='file_name'), pd.DataFrame.from_records(seg_records, index='file_name')])\n",
    "        else:\n",
    "            seg_sec_df = pd.DataFrame.from_records(seg_records, index='file_name')\n",
    "        seg_sec_df.to_csv(seg_df_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_segments_for_file(fd):\n",
    "    fmt = 'wav'\n",
    "    if fd.filename[-4:].lower() == '.mp3' :\n",
    "        fmt = 'mp3'\n",
    "    audio_seg = AudioSegment.from_file(get_fname(fd), format=fmt)\n",
    "\n",
    "    # now condition the segment and extract the raw segments.\n",
    "    audio_seg = condition_audio_segment(audio_seg)\n",
    "    segs = read_the_segment_info(fd)\n",
    "    if len(segs) == 0:\n",
    "        segs = extract_voice_segments(get_fname(fd))\n",
    "        save_the_segment_info(fd, segs)\n",
    "\n",
    "    return audio_seg, segs\n",
    "\n",
    "\n",
    "def create_mp3_files(audio_seg, segs, time_per_segment, dataset_dir, fd):\n",
    "    epochs_for_time = speech_epochs_from_segments(segs, epoch_length=time_per_segment, silence_tolerance=time_per_segment/4.0)\n",
    "\n",
    "    # now write out the 4 sec segments\n",
    "    dirname = prepare_dataset_data_dir(fd, dataset_dir)\n",
    "    rows = list()\n",
    "\n",
    "    for i, seg in enumerate(epochs_for_time):\n",
    "        file_name = dataset_dir + fd.iso + '/' + seg_mp3_filename(fd, i)\n",
    "        fname = dirname + seg_mp3_filename(fd, i)\n",
    "        start = convert_to_ms(seg.start)\n",
    "        stop = convert_to_ms(seg.end)\n",
    "        if not os.path.exists(fname):\n",
    "            audio_seg[start:stop].export(fname, format='mp3', bitrate='32k')\n",
    "        desc = dict(fd._asdict())\n",
    "        desc['seg_start'] = start\n",
    "        desc['seg_stop'] = stop\n",
    "        desc['seg'] = i\n",
    "        desc['file_name'] = file_name\n",
    "        rows.append(desc)\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing these items might take a very long time. To permit the process to be interrupted and restarted the indexes of processed items\n",
    "# are maintained in a set that is pickled on each batch. This allows the batch to quickly pick up where it left off.\n",
    "def process_record_batch(files_df, *, batch_size=10):\n",
    "    batch_proc = 0\n",
    "    processed_file = f'{SEGMENTS_DIR}processed16_{NOTEBOOK_ID}.pkl'\n",
    "    if os.path.isfile(processed_file):\n",
    "        with open(processed_file, 'rb') as pklFile:\n",
    "            processed_files = pkl.load(pklFile)\n",
    "    else:\n",
    "        processed_files = set()\n",
    "\n",
    "    segmented_4sec_segs = []\n",
    "    segmented_6sec_segs = []\n",
    "    segmented_10sec_segs = []\n",
    "\n",
    "    for fd in files_df.itertuples():\n",
    "        if batch_proc < batch_size:\n",
    "            if fd.Index not in processed_files:\n",
    "                try:\n",
    "                    audio_seg, voice_segs = extract_audio_segments_for_file(fd)\n",
    "\n",
    "                    segmented_4sec_segs.extend(create_mp3_files(audio_seg, voice_segs, SEG_4_SEC, SEC_4_DATA_DIR, fd))\n",
    "                    segmented_6sec_segs.extend(create_mp3_files(audio_seg, voice_segs, SEG_6_SEC, SEC_6_DATA_DIR, fd))\n",
    "                    segmented_10sec_segs.extend(create_mp3_files(audio_seg, voice_segs, SEG_10_SEC, SEC_10_DATA_DIR, fd))\n",
    "                except:\n",
    "                    print(f'exception {fd.filename}')\n",
    "                    pass\n",
    "\n",
    "                # we want to add an fd that has an exception so it is not reprocessed on every batch\n",
    "                processed_files.add(fd.Index)\n",
    "                batch_proc += 1\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    update_dataframes(SEG_4_SEC_DF, segmented_4sec_segs)\n",
    "    update_dataframes(SEG_6_SEC_DF, segmented_6sec_segs)\n",
    "    update_dataframes(SEG_10_SEC_DF, segmented_10sec_segs)\n",
    "\n",
    "    with open(processed_file, 'wb') as pklFile:\n",
    "        pkl.dump(processed_files, pklFile)\n",
    "\n",
    "    return processed_files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8250 out of 20837 in 1908.0335907936096 seconds\n",
      "Processed 8300 out of 20837 in 2340.275629758835 seconds\n",
      "Processed 8350 out of 20837 in 3256.0668437480927 seconds\n",
      "Processed 8400 out of 20837 in 4392.923491001129 seconds\n",
      "Processed 8450 out of 20837 in 4928.199355125427 seconds\n",
      "Processed 8500 out of 20837 in 5378.921854019165 seconds\n",
      "Processed 8550 out of 20837 in 5772.326780557632 seconds\n",
      "Processed 8600 out of 20837 in 6416.968067407608 seconds\n",
      "Processed 8650 out of 20837 in 6787.289946317673 seconds\n",
      "Processed 8700 out of 20837 in 7178.666442632675 seconds\n",
      "Processed 8750 out of 20837 in 7642.612494945526 seconds\n",
      "Processed 8800 out of 20837 in 8760.30870604515 seconds\n",
      "Processed 8850 out of 20837 in 10221.758357286453 seconds\n",
      "Processed 8900 out of 20837 in 10734.529624938965 seconds\n",
      "Processed 8950 out of 20837 in 11182.139820337296 seconds\n",
      "Processed 9000 out of 20837 in 11938.666539430618 seconds\n",
      "Processed 9050 out of 20837 in 12950.234704732895 seconds\n",
      "Processed 9100 out of 20837 in 13323.295976638794 seconds\n",
      "Processed 9150 out of 20837 in 14495.033296585083 seconds\n",
      "Processed 9200 out of 20837 in 15920.72177195549 seconds\n",
      "Processed 9250 out of 20837 in 16332.928344249725 seconds\n",
      "Processed 9300 out of 20837 in 17209.324308156967 seconds\n",
      "Processed 9350 out of 20837 in 19100.733911275864 seconds\n",
      "Processed 9400 out of 20837 in 20127.753670930862 seconds\n",
      "Processed 9450 out of 20837 in 20955.38555908203 seconds\n",
      "Processed 9500 out of 20837 in 21295.342836380005 seconds\n",
      "Processed 9550 out of 20837 in 22205.198503255844 seconds\n",
      "Processed 9600 out of 20837 in 24165.08034515381 seconds\n",
      "Processed 9650 out of 20837 in 24586.99381875992 seconds\n",
      "Processed 9700 out of 20837 in 25148.147134542465 seconds\n",
      "Processed 9750 out of 20837 in 25572.654488801956 seconds\n",
      "Processed 9800 out of 20837 in 25932.514399528503 seconds\n",
      "Processed 9850 out of 20837 in 26354.709279060364 seconds\n",
      "Processed 9900 out of 20837 in 26770.17164826393 seconds\n",
      "Processed 9950 out of 20837 in 27131.15439772606 seconds\n",
      "Processed 10000 out of 20837 in 27453.77288222313 seconds\n",
      "Processed 10050 out of 20837 in 28451.202325820923 seconds\n",
      "Processed 10100 out of 20837 in 28841.239587545395 seconds\n",
      "Processed 10150 out of 20837 in 29320.767369747162 seconds\n",
      "Processed 10200 out of 20837 in 30611.590051412582 seconds\n",
      "Processed 10250 out of 20837 in 31786.39025902748 seconds\n",
      "Processed 10300 out of 20837 in 32915.88609838486 seconds\n",
      "Processed 10350 out of 20837 in 33831.23042368889 seconds\n",
      "Processed 10400 out of 20837 in 34634.96282720566 seconds\n",
      "Processed 10450 out of 20837 in 35136.6998796463 seconds\n",
      "Processed 10500 out of 20837 in 36140.06362700462 seconds\n",
      "Processed 10550 out of 20837 in 37203.604799985886 seconds\n",
      "Processed 10600 out of 20837 in 38761.19820213318 seconds\n",
      "Processed 10650 out of 20837 in 40139.45893788338 seconds\n",
      "Processed 10700 out of 20837 in 40585.92568254471 seconds\n",
      "Processed 10750 out of 20837 in 41833.87216711044 seconds\n",
      "Processed 10800 out of 20837 in 42535.87881040573 seconds\n",
      "Processed 10850 out of 20837 in 44739.252938985825 seconds\n",
      "Processed 10900 out of 20837 in 45261.162645339966 seconds\n",
      "Processed 10950 out of 20837 in 45938.963240623474 seconds\n",
      "Processed 11000 out of 20837 in 46770.88423418999 seconds\n",
      "Processed 11050 out of 20837 in 47330.51646351814 seconds\n",
      "Processed 11100 out of 20837 in 49661.45208787918 seconds\n",
      "Processed 11150 out of 20837 in 50975.03991961479 seconds\n",
      "Processed 11200 out of 20837 in 51643.72577238083 seconds\n",
      "Processed 11250 out of 20837 in 53131.66639518738 seconds\n",
      "Processed 11300 out of 20837 in 54894.07963705063 seconds\n",
      "Processed 11350 out of 20837 in 56157.99885106087 seconds\n",
      "Processed 11400 out of 20837 in 56701.11635327339 seconds\n",
      "Processed 11450 out of 20837 in 57613.16845345497 seconds\n",
      "Processed 11500 out of 20837 in 58288.977684020996 seconds\n",
      "Processed 11550 out of 20837 in 59262.83588767052 seconds\n",
      "Processed 11600 out of 20837 in 60031.633574962616 seconds\n",
      "Processed 11650 out of 20837 in 60452.908658742905 seconds\n",
      "Processed 11700 out of 20837 in 61280.90320420265 seconds\n",
      "Processed 11750 out of 20837 in 62303.34169173241 seconds\n",
      "Processed 11800 out of 20837 in 62908.809910297394 seconds\n",
      "Processed 11850 out of 20837 in 63788.96988725662 seconds\n",
      "Processed 11900 out of 20837 in 64337.29181051254 seconds\n",
      "Processed 11950 out of 20837 in 64861.2248044014 seconds\n",
      "Processed 12000 out of 20837 in 65841.75255584717 seconds\n",
      "Processed 12050 out of 20837 in 66457.06968736649 seconds\n",
      "Processed 12100 out of 20837 in 66980.81528687477 seconds\n",
      "Processed 12150 out of 20837 in 67787.4700577259 seconds\n",
      "Processed 12200 out of 20837 in 68322.17743086815 seconds\n",
      "Processed 12250 out of 20837 in 68735.1573934555 seconds\n",
      "Processed 12300 out of 20837 in 69168.46480751038 seconds\n",
      "Processed 12350 out of 20837 in 70252.91082787514 seconds\n",
      "Processed 12400 out of 20837 in 70704.74220967293 seconds\n",
      "Processed 12450 out of 20837 in 71426.37716436386 seconds\n",
      "Processed 12500 out of 20837 in 72772.63585662842 seconds\n",
      "Processed 12550 out of 20837 in 73554.40091729164 seconds\n",
      "Processed 12600 out of 20837 in 74306.11928248405 seconds\n",
      "Processed 12650 out of 20837 in 74906.64920544624 seconds\n",
      "Processed 12700 out of 20837 in 75311.1754257679 seconds\n",
      "Processed 12750 out of 20837 in 76129.78966474533 seconds\n",
      "Processed 12800 out of 20837 in 76914.46780705452 seconds\n",
      "Processed 12850 out of 20837 in 77564.24421143532 seconds\n",
      "Processed 12900 out of 20837 in 78007.06506514549 seconds\n",
      "Processed 12950 out of 20837 in 78378.0035674572 seconds\n",
      "Processed 13000 out of 20837 in 78947.40638017654 seconds\n",
      "Processed 13050 out of 20837 in 79296.45298933983 seconds\n",
      "Processed 13100 out of 20837 in 79628.4726421833 seconds\n",
      "Processed 13150 out of 20837 in 80161.47106575966 seconds\n",
      "Processed 13200 out of 20837 in 80947.8975455761 seconds\n",
      "Processed 13250 out of 20837 in 81475.36568403244 seconds\n",
      "Processed 13300 out of 20837 in 81971.78170967102 seconds\n",
      "Processed 13350 out of 20837 in 82520.23820114136 seconds\n",
      "Processed 13400 out of 20837 in 83290.78707456589 seconds\n",
      "Processed 13450 out of 20837 in 83987.71719312668 seconds\n",
      "Processed 13500 out of 20837 in 84389.60053682327 seconds\n",
      "Processed 13550 out of 20837 in 84855.96466875076 seconds\n",
      "Processed 13600 out of 20837 in 85260.1647439003 seconds\n",
      "Processed 13650 out of 20837 in 86352.5518553257 seconds\n",
      "Processed 13700 out of 20837 in 87117.7897734642 seconds\n",
      "Processed 13750 out of 20837 in 88165.10109424591 seconds\n",
      "Processed 13800 out of 20837 in 88697.30631995201 seconds\n",
      "Processed 13850 out of 20837 in 89915.38117814064 seconds\n",
      "Processed 13900 out of 20837 in 91037.83702015877 seconds\n",
      "Processed 13950 out of 20837 in 92598.41490244865 seconds\n",
      "Processed 14000 out of 20837 in 93292.96744179726 seconds\n",
      "Processed 14050 out of 20837 in 94240.73906755447 seconds\n",
      "Processed 14100 out of 20837 in 95189.9308321476 seconds\n",
      "Processed 14150 out of 20837 in 96431.32260489464 seconds\n",
      "Processed 14200 out of 20837 in 96785.88240861893 seconds\n",
      "Processed 14250 out of 20837 in 97381.52849721909 seconds\n",
      "Processed 14300 out of 20837 in 97997.21208381653 seconds\n",
      "Processed 14350 out of 20837 in 98904.17308473587 seconds\n",
      "Processed 14400 out of 20837 in 99599.60128331184 seconds\n",
      "Processed 14450 out of 20837 in 100300.73324918747 seconds\n",
      "Processed 14500 out of 20837 in 100883.15074396133 seconds\n",
      "Processed 14550 out of 20837 in 101444.57865738869 seconds\n",
      "Processed 14600 out of 20837 in 102409.56587219238 seconds\n",
      "Processed 14650 out of 20837 in 102947.18213558197 seconds\n",
      "Processed 14700 out of 20837 in 103610.7895886898 seconds\n",
      "Processed 14750 out of 20837 in 104242.06137537956 seconds\n",
      "Processed 14800 out of 20837 in 104920.20890235901 seconds\n",
      "Processed 14850 out of 20837 in 105544.36710047722 seconds\n",
      "Processed 14900 out of 20837 in 106863.34808325768 seconds\n",
      "Processed 14950 out of 20837 in 108127.8572063446 seconds\n",
      "Processed 15000 out of 20837 in 108877.31948280334 seconds\n",
      "Processed 15050 out of 20837 in 109807.20529913902 seconds\n",
      "Processed 15100 out of 20837 in 111847.19255757332 seconds\n",
      "Processed 15150 out of 20837 in 112535.38029098511 seconds\n",
      "Processed 15200 out of 20837 in 113183.94869303703 seconds\n",
      "Processed 15250 out of 20837 in 113528.76677751541 seconds\n",
      "Processed 15300 out of 20837 in 114006.57835412025 seconds\n",
      "Processed 15350 out of 20837 in 116027.90661931038 seconds\n",
      "Processed 15400 out of 20837 in 116845.39892816544 seconds\n",
      "Processed 15450 out of 20837 in 117715.53010058403 seconds\n",
      "Processed 15500 out of 20837 in 118187.0072362423 seconds\n",
      "Processed 15550 out of 20837 in 120545.82223129272 seconds\n",
      "Processed 15600 out of 20837 in 121403.97392225266 seconds\n",
      "Processed 15650 out of 20837 in 122557.99208045006 seconds\n",
      "Processed 15700 out of 20837 in 124351.21534657478 seconds\n",
      "exception A65933-001.wav\n",
      "exception A65933-013.wav\n",
      "exception A65933-019.wav\n",
      "exception A65933-018.wav\n",
      "exception A65933-017.wav\n",
      "Processed 15750 out of 20837 in 125855.7147436142 seconds\n",
      "exception A65933-011.wav\n",
      "exception A65933-002.wav\n",
      "exception A65933-012.wav\n",
      "exception A65933-008.wav\n",
      "Processed 15800 out of 20837 in 126359.48708605766 seconds\n",
      "Processed 15850 out of 20837 in 130764.64079976082 seconds\n",
      "Processed 15900 out of 20837 in 133110.61955690384 seconds\n",
      "Processed 15950 out of 20837 in 133580.03697562218 seconds\n",
      "Processed 16000 out of 20837 in 134407.3778913021 seconds\n",
      "Processed 16050 out of 20837 in 134857.47817015648 seconds\n",
      "Processed 16100 out of 20837 in 135298.2192554474 seconds\n",
      "Processed 16150 out of 20837 in 136040.55575084686 seconds\n",
      "Processed 16200 out of 20837 in 136654.72790074348 seconds\n",
      "Processed 16250 out of 20837 in 137100.76042294502 seconds\n",
      "Processed 16300 out of 20837 in 137699.33668589592 seconds\n",
      "Processed 16350 out of 20837 in 138474.43056845665 seconds\n",
      "Processed 16400 out of 20837 in 139800.77175712585 seconds\n",
      "Processed 16450 out of 20837 in 140723.67885923386 seconds\n",
      "Processed 16500 out of 20837 in 143041.42586421967 seconds\n",
      "Processed 16550 out of 20837 in 143489.34366321564 seconds\n",
      "Processed 16600 out of 20837 in 144030.92735123634 seconds\n",
      "Processed 16650 out of 20837 in 144621.76222538948 seconds\n",
      "Processed 16700 out of 20837 in 146597.21808815002 seconds\n",
      "Processed 16750 out of 20837 in 147960.3941400051 seconds\n",
      "Processed 16800 out of 20837 in 149185.38498330116 seconds\n",
      "Processed 16850 out of 20837 in 149744.15728878975 seconds\n",
      "Processed 16900 out of 20837 in 150546.5471048355 seconds\n",
      "Processed 16950 out of 20837 in 151049.35196828842 seconds\n",
      "Processed 17000 out of 20837 in 151858.8271021843 seconds\n",
      "Processed 17050 out of 20837 in 152734.5561504364 seconds\n",
      "Processed 17100 out of 20837 in 153493.62261724472 seconds\n",
      "Processed 17150 out of 20837 in 154452.97803282738 seconds\n",
      "Processed 17200 out of 20837 in 155191.92077732086 seconds\n",
      "Processed 17250 out of 20837 in 156087.07230901718 seconds\n",
      "Processed 17300 out of 20837 in 156522.95904636383 seconds\n",
      "Processed 17350 out of 20837 in 157302.65340828896 seconds\n",
      "Processed 17400 out of 20837 in 158011.75055670738 seconds\n",
      "Processed 17450 out of 20837 in 159811.30258893967 seconds\n",
      "Processed 17500 out of 20837 in 161169.2800757885 seconds\n",
      "Processed 17550 out of 20837 in 162111.57365250587 seconds\n",
      "Processed 17600 out of 20837 in 162553.8953793049 seconds\n",
      "Processed 17650 out of 20837 in 164505.59694838524 seconds\n",
      "Processed 17700 out of 20837 in 164970.2210202217 seconds\n",
      "Processed 17750 out of 20837 in 165411.08372187614 seconds\n",
      "Processed 17800 out of 20837 in 165889.92123556137 seconds\n",
      "Processed 17850 out of 20837 in 166684.2268974781 seconds\n",
      "Processed 17900 out of 20837 in 166990.93869185448 seconds\n",
      "Processed 17950 out of 20837 in 167531.59935879707 seconds\n",
      "Processed 18000 out of 20837 in 170570.01238322258 seconds\n",
      "Processed 18050 out of 20837 in 171069.4458732605 seconds\n",
      "Processed 18100 out of 20837 in 171633.8283751011 seconds\n",
      "Processed 18150 out of 20837 in 172854.95465755463 seconds\n",
      "Processed 18200 out of 20837 in 173361.31027674675 seconds\n",
      "Processed 18250 out of 20837 in 174215.86496949196 seconds\n",
      "Processed 18300 out of 20837 in 174616.6322901249 seconds\n",
      "Processed 18350 out of 20837 in 175072.33309030533 seconds\n",
      "Processed 18400 out of 20837 in 175538.34102416039 seconds\n",
      "Processed 18450 out of 20837 in 176061.91734552383 seconds\n",
      "Processed 18500 out of 20837 in 176818.44975304604 seconds\n",
      "Processed 18550 out of 20837 in 178123.70579576492 seconds\n",
      "Processed 18600 out of 20837 in 178543.8899834156 seconds\n",
      "Processed 18650 out of 20837 in 179333.10951399803 seconds\n",
      "Processed 18700 out of 20837 in 180232.4566578865 seconds\n",
      "Processed 18750 out of 20837 in 181298.9343791008 seconds\n",
      "Processed 18800 out of 20837 in 182071.3512635231 seconds\n",
      "Processed 18850 out of 20837 in 182465.50924634933 seconds\n",
      "Processed 18900 out of 20837 in 182900.8937778473 seconds\n",
      "Processed 18950 out of 20837 in 183442.46991968155 seconds\n",
      "Processed 19000 out of 20837 in 184021.36901187897 seconds\n",
      "Processed 19050 out of 20837 in 184532.8385720253 seconds\n",
      "Processed 19100 out of 20837 in 184985.28334069252 seconds\n",
      "Processed 19150 out of 20837 in 185365.66155171394 seconds\n",
      "Processed 19200 out of 20837 in 186797.6645667553 seconds\n",
      "Processed 19250 out of 20837 in 187502.12232899666 seconds\n",
      "Processed 19300 out of 20837 in 188911.19151568413 seconds\n",
      "Processed 19350 out of 20837 in 190121.74926185608 seconds\n",
      "Processed 19400 out of 20837 in 194385.96662926674 seconds\n",
      "Processed 19450 out of 20837 in 196150.46698474884 seconds\n",
      "Processed 19500 out of 20837 in 196833.74508619308 seconds\n",
      "Processed 19550 out of 20837 in 197991.35209035873 seconds\n",
      "Processed 19600 out of 20837 in 198304.6507205963 seconds\n",
      "Processed 19650 out of 20837 in 198988.21884131432 seconds\n",
      "Processed 19700 out of 20837 in 199904.70632457733 seconds\n",
      "Processed 19750 out of 20837 in 200874.86526823044 seconds\n",
      "Processed 19800 out of 20837 in 201425.18607521057 seconds\n",
      "Processed 19850 out of 20837 in 201718.25330972672 seconds\n",
      "Processed 19900 out of 20837 in 202744.01767015457 seconds\n",
      "Processed 19950 out of 20837 in 203709.1316833496 seconds\n",
      "Processed 20000 out of 20837 in 204685.02916955948 seconds\n",
      "Processed 20050 out of 20837 in 205256.92043733597 seconds\n",
      "Processed 20100 out of 20837 in 205591.2080552578 seconds\n",
      "Processed 20150 out of 20837 in 205878.36861419678 seconds\n",
      "Processed 20200 out of 20837 in 206272.0925424099 seconds\n",
      "Processed 20250 out of 20837 in 206925.80709719658 seconds\n",
      "Processed 20300 out of 20837 in 207841.86568403244 seconds\n",
      "Processed 20350 out of 20837 in 208842.30497169495 seconds\n",
      "Processed 20400 out of 20837 in 209687.26872825623 seconds\n",
      "Processed 20450 out of 20837 in 210290.96401929855 seconds\n",
      "Processed 20500 out of 20837 in 210931.82961940765 seconds\n",
      "Processed 20550 out of 20837 in 211456.18018770218 seconds\n",
      "Processed 20600 out of 20837 in 211843.91097307205 seconds\n",
      "Processed 20650 out of 20837 in 212679.92323803902 seconds\n",
      "Processed 20700 out of 20837 in 213369.29975891113 seconds\n",
      "Processed 20750 out of 20837 in 214202.7668671608 seconds\n",
      "Processed 20800 out of 20837 in 215235.87627482414 seconds\n",
      "Processed 20837 out of 20837 in 215574.4917755127 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# form the language classification file\n",
    "files_processed = 0\n",
    "files_to_process = len(fd)\n",
    "while files_to_process > files_processed:\n",
    "    processed_files = process_record_batch(fd, batch_size=50)\n",
    "    files_processed = len(processed_files)\n",
    "    print(f'Processed {files_processed} out of {files_to_process} in {time.time()-start_time} seconds')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyAudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2abc5501ad3d8eff2da7865cf45fd15699605a857f48109c31373cdc3963a944"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

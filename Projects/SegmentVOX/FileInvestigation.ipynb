{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Investigation\n",
    "The purpose of this file is to investigate using the file description to build a datbase.\n",
    "\n",
    "The following assumptions are to be tested:\n",
    "1. Each file has only one language.\n",
    "2. Our VAD can correctly discern music from voice.\n",
    "3. For single item files can we discard instrumentals/announcements reliably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import spleeter\n",
    "from collections import namedtuple\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../vad_utils'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from vad_utils import SAMPLING_RATE, FRAME_SIZE_MS, SAMPLES_PER_FRAME\n",
    "import vad_utils as vu\n",
    "from pydub import AudioSegment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The columns of records are:\n",
      "Index(['Unnamed: 0.1', 'Unnamed: 0', 'iso', 'language_name', 'track',\n",
      "       'location', 'year', 'path', 'filename', 'length', 'program', 'ID'],\n",
      "      dtype='object')\n",
      "Program items shape: (267681, 21)\n"
     ]
    }
   ],
   "source": [
    "fd = pd.read_csv(\"../../data/records_with_voxgrn_files.csv\")\n",
    "print(f'The columns of records are:\\n{fd.columns}')\n",
    "items = pd.read_csv(\"/prometheus/GRN/grid_program_items.csv\")\n",
    "print(f'Program items shape: {items.shape}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many files have a duplicate ID?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate files 0\n"
     ]
    }
   ],
   "source": [
    "print(f'Duplicate files {sum(fd.ID.duplicated(keep=\"first\"))}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start by looking at the third assumption. Can we identify files that are purely unwanted types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "items['program'] = items['Program Number'].str[1:]\n",
    "items['ID'] = items['program'] + '_' + items['Track Number'].astype(int).apply('{:0>3d}'.format)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now recreate the file merged version without dropping unwanted types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_with_records = pd.merge(fd, items, on=\"ID\", how='inner', validate='1:m')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compound items 56937\n"
     ]
    }
   ],
   "source": [
    "items_with_records['compound'] = items_with_records.duplicated(subset=['path', 'filename'], keep=False)\n",
    "print(f'Compound items {sum(items_with_records.compound)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now mark the items based on their usability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the 4405 unusable items, 1221 are in single files.\n"
     ]
    }
   ],
   "source": [
    "def usable_types(item_row):\n",
    "    unusable_items = ['Instrumental', 'Sound Effect', 'Announcement', 'Bridge']\n",
    "    return item_row['Item Type'] not in unusable_items\n",
    "\n",
    "items_with_records['usable'] = items_with_records.apply(usable_types, axis=1)\n",
    "\n",
    "print(f'Of the {sum(~items_with_records.usable)} unusable items, {sum(~items_with_records.usable & ~items_with_records.compound)} are in single files.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_file_unusable = items_with_records[~items_with_records.usable & ~items_with_records.compound]\n",
    "multi_file_unusable = items_with_records[~items_with_records.usable & items_with_records.compound]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check the single file items found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Programs/03/03111/A03111/From_CM/ C03111B Region 00_10_37_802 to 00_10_53_562 (04 _ 05).wav\n",
      "Programs/03/03110/A03110/From_CM/ C03110A Region 00_13_28_106 to 00_13_42_805 (06 _ 07).wav\n",
      "Programs/03/03410/A03410/From_CM/ C03410A-02.wav\n",
      "Programs/66/66533/A66533/PM-1407/ A66533-001_Dubli_Introduction.wav\n",
      "Programs/65/65951/A65951/PM-1810/ A65951-009.wav\n"
     ]
    }
   ],
   "source": [
    "print(f'{single_file_unusable.iloc[0].path} {single_file_unusable.iloc[0].filename}')\n",
    "print(f'{single_file_unusable.iloc[1].path} {single_file_unusable.iloc[1].filename}')\n",
    "print(f'{single_file_unusable.iloc[2].path} {single_file_unusable.iloc[2].filename}')\n",
    "print(f'{single_file_unusable.iloc[3].path} {single_file_unusable.iloc[3].filename}')\n",
    "print(f'{single_file_unusable.iloc[4].path} {single_file_unusable.iloc[4].filename}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are announcements always in the language?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "announcements = single_file_unusable[single_file_unusable['Item Type'].str.contains('Announcement')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Programs/66/66533/A66533/PM-1407/ A66533-001_Dubli_Introduction.wav\n",
      "Programs/65/65540/A65540/PM-1706/ A65540-001.wav\n",
      "Programs/65/65539/A65539/PM-1706/ A65539-001.wav\n",
      "Programs/65/65538/A65538/PM-1706/ A65538-001.wav\n",
      "Programs/65/65537/A65537/PM-1706/ A65537-001.wav\n"
     ]
    }
   ],
   "source": [
    "print(f'{announcements.iloc[0].path} {announcements.iloc[0].filename}')\n",
    "print(f'{announcements.iloc[1].path} {announcements.iloc[1].filename}')\n",
    "print(f'{announcements.iloc[2].path} {announcements.iloc[2].filename}')\n",
    "print(f'{announcements.iloc[3].path} {announcements.iloc[3].filename}')\n",
    "print(f'{announcements.iloc[4].path} {announcements.iloc[4].filename}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No - sometimes they are in English."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at files that contain mixed items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Programs/03/03111/A03111/From_CM/ C03111B Region 00_14_24_256 to 00_18_27_327 (06 _ 07).wav\n",
      "Programs/03/03111/A03111/From_CM/ C03111B Region 00_18_27_328 to 00_22_19_986 (07 _ 08).wav\n",
      "Programs/03/03111/A03111/From_CM/ C03111 Region 00_11_05_088 to 00_14_58_047 (04 _ 05).wav\n",
      "Programs/03/03351/C03351/PM/ 03351.wav\n",
      "Programs/03/03381/C03381/Copy_From_MP3_CM/ C03381A.wav\n"
     ]
    }
   ],
   "source": [
    "print(f'{multi_file_unusable.iloc[0].path} {multi_file_unusable.iloc[0].filename}')\n",
    "print(f'{multi_file_unusable.iloc[1].path} {multi_file_unusable.iloc[1].filename}')\n",
    "print(f'{multi_file_unusable.iloc[2].path} {multi_file_unusable.iloc[2].filename}')\n",
    "print(f'{multi_file_unusable.iloc[3].path} {multi_file_unusable.iloc[3].filename}')\n",
    "print(f'{multi_file_unusable.iloc[4].path} {multi_file_unusable.iloc[4].filename}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you can have some instrumentals - we need to be able to reject them.\n",
    "\n",
    "Waht about announcements - are they ever embedded in files with useful data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_announcements = multi_file_unusable[multi_file_unusable['Item Type'].str.contains('Announcement')].copy()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are all announcements embedded in other files in the language of the file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Programs/03/03351/C03351/PM/ 03351.wav\n",
      "Programs/62/62537/A62537/PM/ A62537-01.wav\n",
      "Programs/62/62537/A62537/PM/ A62537-11.wav\n",
      "Programs/62/62537/A62537/PM/ A62537-24.wav\n",
      "Programs/66/66224/A66224/PM-1904/ A66224-001.wav\n"
     ]
    }
   ],
   "source": [
    "print(f'{multi_announcements.iloc[0].path} {multi_announcements.iloc[0].filename}')\n",
    "print(f'{multi_announcements.iloc[1].path} {multi_announcements.iloc[1].filename}')\n",
    "print(f'{multi_announcements.iloc[2].path} {multi_announcements.iloc[2].filename}')\n",
    "print(f'{multi_announcements.iloc[3].path} {multi_announcements.iloc[3].filename}')\n",
    "print(f'{multi_announcements.iloc[4].path} {multi_announcements.iloc[4].filename}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there often seems to be a short announcement at the start of the file. SHould I mark these? It could be useful - time to discard.\n",
    "Are all of these announcements at the start of the files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Announcement at the start of 45 of 363 files\n"
     ]
    }
   ],
   "source": [
    "def announcement_is_at_start(item):\n",
    "    global items_with_records\n",
    "    multi_items = items_with_records[items_with_records['filename'] == item['filename']].copy()\n",
    "    multi_items['Item Start Time'] = multi_items['Item Start Time'].fillna('0:00')\n",
    "    multi_items = multi_items.sort_values(by='Item Start Time')\n",
    "    return multi_items.iloc[0]['Item Type'] == 'Announcement'\n",
    "\n",
    "multi_announcements['Announce at start'] = multi_announcements.apply(announcement_is_at_start, axis=1)\n",
    "\n",
    "print(f'Announcement at the start of {sum(multi_announcements[\"Announce at start\"])} of {len(multi_announcements)} files')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to File\n",
    "To consolidate this lets create a new file descriptor file without the single file announcements and instrumentals.\n",
    "\n",
    "To do this I want to filter out the file descriptors associated with single items and are unusable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1221 files out of 210488 are unusable.\n"
     ]
    }
   ],
   "source": [
    "fd['unusable'] = fd['ID'].isin(single_file_unusable.ID)\n",
    "print(f'{sum(fd.unusable)} files out of {len(fd)} are unusable.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0.1', 'Unnamed: 0', 'iso', 'language_name', 'track',\n",
      "       'location', 'year', 'path', 'filename', 'length', 'program', 'ID',\n",
      "       'unusable'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(fd.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "usable_fd = fd[~fd.unusable].copy()\n",
    "usable_fd.drop(columns=['Unnamed: 0.1', 'Unnamed: 0', 'unusable'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "usable_fd.to_csv('../../data/usable_files.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAD Testing.\n",
    "\n",
    "* Test how well our VAD does at rejecting instrumentals.\n",
    "* Test the effect of altering its sensitivity.\n",
    "* See what VAD does with singing and background instumentals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 196150 single item files. Found 2692 instrumental files. Found 1057 single instrumnetal files. Total files 210488.\n"
     ]
    }
   ],
   "source": [
    "# find instrumental files\n",
    "single_file_items = items_with_records[~items_with_records.compound]\n",
    "instrumental_items = items_with_records[items_with_records['Item Type'] == 'Instrumental']\n",
    "fd['single'] = fd.ID.isin(single_file_items.ID)\n",
    "fd['instrumental'] = fd.ID.isin(instrumental_items.ID)\n",
    "single_instrumental_files = fd[fd.single & fd.instrumental]\n",
    "\n",
    "print(f'Found {sum(fd.single)} single item files. Found {sum(fd.instrumental)} instrumental files. Found {len(single_instrumental_files)} single instrumnetal files. Total files {len(fd)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def condition_audio_segment(audio_seg):\n",
    "    if audio_seg.channels != 1:\n",
    "        audio_seg = audio_seg.set_channels(1)\n",
    "\n",
    "    if audio_seg.sample_width != 2:\n",
    "        audio_seg = audio_seg.set_sample_width(2)\n",
    "\n",
    "    if audio_seg.frame_rate != SAMPLING_RATE:\n",
    "        audio_seg = audio_seg.set_frame_rate(SAMPLING_RATE)\n",
    "\n",
    "    return audio_seg\n",
    "        \n",
    "\n",
    "def extract_audio_segment_for_file(fd, sensitivity=2):\n",
    "    fmt = 'wav'\n",
    "    if fd.filename[-4:].lower() == '.mp3' :\n",
    "        fmt = 'mp3'\n",
    "    if not fd.path.endswith('/'):\n",
    "        path = fd.path + '/'\n",
    "    else:\n",
    "        path = fd.path\n",
    "    audio_seg = AudioSegment.from_file('/media/programs/' + path + fd.filename, format=fmt)\n",
    "\n",
    "    # now condition the segment and extract the raw segments.\n",
    "    audio_seg = condition_audio_segment(audio_seg)\n",
    "    segs = vu.audio_to_raw_voice_segments(audio_seg, sensitivity)\n",
    "\n",
    "    return audio_seg, segs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find some segments\n",
    "segs = list()\n",
    "Desc = namedtuple('Desc', ['sens', 'start', 'stop', 'path', 'file'])\n",
    "for sens in range(4):\n",
    "    for fd in single_instrumental_files.itertuples():\n",
    "        audio_seg, voice_segs = extract_audio_segment_for_file(fd, sens)\n",
    "        segs_for_time = vu.divide_into_segments(voice_segs, 4.0)\n",
    "        for i, seg in enumerate(segs_for_time):\n",
    "            start = vu.convert_frames_to_ms(seg.start)\n",
    "            stop = vu.convert_frames_to_ms(seg.stop)\n",
    "            segs.append(Desc(sens, start, stop, fd.path, fd.filename))\n",
    "    else:\n",
    "        if len(segs_for_time) == 0:\n",
    "            print(f'{sens}: No segments {fd.path} {fd.filename}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'pretrained_models/2stems', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.7\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Apply unet for vocals_spectrogram\n",
      "INFO:tensorflow:Apply unet for accompaniment_spectrogram\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from pretrained_models/2stems/model\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:spleeter:File ../../data/spleeter/C03111B Region 00_10_37_802 to 00_10_53_562 (04 _ 05)/vocals.wav written succesfully\n",
      "INFO:spleeter:File ../../data/spleeter/C03111B Region 00_10_37_802 to 00_10_53_562 (04 _ 05)/accompaniment.wav written succesfully\n"
     ]
    }
   ],
   "source": [
    "from spleeter.separator import Separator\n",
    "# test out using spleeter\n",
    "# Load the spleeter configuration for vocal separation\n",
    "separator = Separator('spleeter:2stems')\n",
    "\n",
    "# Load the input audio file\n",
    "input_file = '/media/programs/' + single_instrumental_files.iloc[0].path + single_instrumental_files.iloc[0].filename\n",
    "\n",
    "# Use spleeter to separate the vocals from the input file\n",
    "separator.separate_to_file(input_file, '../../data/spleeter')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 4290\n"
     ]
    }
   ],
   "source": [
    "# now see how vad handles the separated file\n",
    "fake_fd = namedtuple('fake_fd', ['path', 'filename'])\n",
    "dummy_fd = fake_fd('../../data/spleeter/C03111B Region 00_10_37_802 to 00_10_53_562 (04 _ 05)/', 'vocals.wav')\n",
    "audio_seg, voice_segs = extract_audio_segment_for_file(dummy_fd)\n",
    "segs_for_time = vu.divide_into_segments(voice_segs, 4.0)\n",
    "for i, seg in enumerate(segs_for_time):\n",
    "    start = vu.convert_frames_to_ms(seg.start)\n",
    "    stop = vu.convert_frames_to_ms(seg.stop)\n",
    "    print(f'{start} {stop}')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the list of analysed files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instrumental_files = pd.DataFrame(segs)\n",
    "instrumental_files.to_csv('../../data/instrumenal_file_segs.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These segments will be analysed in Instrumental.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

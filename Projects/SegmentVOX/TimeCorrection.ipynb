{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time correction\n",
    "The item times can be erroneous or missing. This is further compounded by some files containing multiple items. The previous analysis (StandardiseDataAccess.ipynb) relied on knowing which items belonged to files that contained multiple items. This is not a very reliable metric. Therefore in this analysis we do not differentiate based on compound files.\n",
    "\n",
    "The issue appears to be that when an item is a completely contained in a file the start and end times seem to be nonsense - other than their difference is the duration. However, when there are multiple items in the one file the start and end times are used. When an item is the first then the start is commonly NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import json\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gain Input Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program items shape: (248671, 18)\n"
     ]
    }
   ],
   "source": [
    "# Now read in the description of the input and remove the unwanted columns and rename the rest to be python attribute names.\n",
    "\n",
    "items = pd.read_csv(\"../../data/items_with_records_with_voxgrn_files.csv\")\n",
    "print(f'Program items shape: {items.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "items['compound'] = items.duplicated(subset=['path', 'filename'], keep=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try some time functions\n",
    "import re\n",
    "\n",
    "def extract_seconds(_time):\n",
    "    if isinstance(_time, str):\n",
    "        m = re.search(r'([0-9]{1,2})\\:([0-9]{2})', _time)\n",
    "        if m:\n",
    "            min = float(m.group(1))\n",
    "            sec = float(m.group(2))\n",
    "            return min * 60.0 + sec\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "items['start_time'] = items['start'].apply(extract_seconds)\n",
    "items['end_time'] = items['end'].apply(extract_seconds)\n",
    "items['duration_time'] = items['duration'].apply(extract_seconds)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "To correct the start and end times of each item we need to first find any patterns that we can exploit. We know that files that contain multiple items are treated differently.\n",
    "\n",
    "Using items that use the same path and filename will almost certainly find multiple item files. I am calling such items compound items. The issue is does it find them all? Are there items that are the only ones in a file because the other items were removed (for being instrumentals etc.). I know with the new files if there ar multiple items the filename contains diamonds. Lets see how many of them there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items with diamonds that are not marked compound: 1\n"
     ]
    }
   ],
   "source": [
    "print(f'Items with diamonds that are not marked compound: {sum(items[\"filename\"].str.contains(\"♦\") & ~items[\"compound\"])}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just one! Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "odd_compound = items[items[\"filename\"].str.contains(\"♦\") & ~items[\"compound\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other element is an instrumental. Disturbingly the start time is not right.\n",
    "\n",
    "What do we think we know?\n",
    "1. The start time is unreliable in single item files.\n",
    "2. ditto the end time\n",
    "3. end time - start time reliably is the item duration.\n",
    "4. when start time is NaN it is actually zero.\n",
    "5. If we could reliably pick the multiple item files then we could say that their start and end times are correct. (Although the item above shows that this might not be true)\n",
    "\n",
    "Lets test point 5 on the voxgrn data because we know which files contain multiple items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17207, 21)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voxgrn_multi = items[items[\"filename\"].str.contains(\"♦\")].copy()\n",
    "voxgrn_multi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_times(row):\n",
    "    return row.start_time < row.length and row.end_time < row.length\n",
    "\n",
    "voxgrn_multi['valid'] = voxgrn_multi.apply(valid_times, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_multi = voxgrn_multi[voxgrn_multi.valid == False]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK - so the gaps have been removed in the mp3's meaning that the item boundaries do not have any padding. See if changing this corrects the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxgrn_multi.sort_values(by=['ID', 'item'], ascending=[True, True], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_ID = ''\n",
    "accumulated_time = 0\n",
    "def calculate_start_time(row):\n",
    "    global current_ID, accumulated_time\n",
    "    if row.ID != current_ID:\n",
    "        current_ID = row.ID\n",
    "        accumulated_time = 0\n",
    "    start_time = accumulated_time\n",
    "    accumulated_time += row.duration_time\n",
    "    return start_time\n",
    "\n",
    "voxgrn_multi['start_'] = voxgrn_multi.apply(calculate_start_time, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_end_time(row):\n",
    "    return row.start_ + row.duration_time\n",
    "\n",
    "voxgrn_multi['end_'] = voxgrn_multi.apply(calculate_end_time, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which shows (by visual inspection and playing the tracks for alignment) that the original start times are erroneous in both directions (positive and negative) and the duration is NOT always right when applied from the programs to the voxgrn data.\n",
    "\n",
    "what if we apply the same logic to the non-voxgrn data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_multi = items[(items[\"filename\"].str.contains(\"♦\") == False) & (items.compound == True)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_multi.sort_values(by=['ID', 'item'], ascending=[True, True], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulated_time = 0\n",
    "current_ID = ''\n",
    "\n",
    "orig_multi['start_'] = orig_multi.apply(calculate_start_time, axis=1)\n",
    "orig_multi['end_'] = orig_multi.apply(calculate_end_time, axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the first example - program 20 - there is a song for the first 45 seconds which is not in the metadata. The gaps between items do not exist - which means that at the end it is back in sync again. This is poor quality data - the meta data is erroneous.\n",
    "\n",
    "The next program, 30, is similarly erroneous. There is an instrumental completely misplaced at the end of the first message.\n",
    "\n",
    "what does the voice activation program do with the file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

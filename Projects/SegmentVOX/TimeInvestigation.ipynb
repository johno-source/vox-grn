{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Investigation\n",
    "To be able to use the items I need to verify that the start and end times are right.\n",
    "I will divide the times into 3 types for investigation:\n",
    "\n",
    "1. wav files. I first need to verify that the original time correction algorithm worked or not.\n",
    "2. mp3 files. I strongly suspect that these have had dead space removed from them.\n",
    "3. recovered files. I am not sure how the times will line up on these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.8) or chardet (5.1.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pickle as pkl\n",
    "from pathlib import Path\n",
    "import time\n",
    "import glob\n",
    "import json\n",
    "import requests\n",
    "import math\n",
    "from pydub import AudioSegment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The columns of items with records are:\n",
      "Index(['Unnamed: 0', 'iso', 'language_name', 'track', 'location', 'year',\n",
      "       'path', 'filename', 'length', 'ID', 'item', 'title', 'start',\n",
      "       'duration', 'end', 'type', 'program'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "items = pd.read_csv(\"../../data/items_with_records_all.csv\")\n",
    "print(f'The columns of items with records are:\\n{items.columns}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item zero\n",
    "Before starting I have a strong suspicion that item zero is always an announcement in English. How many zeros do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item zero count: 152\n"
     ]
    }
   ],
   "source": [
    "item_zero = items[items['item'] == 0].copy()\n",
    "print(f\"Item zero count: {len(item_zero)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assumption appears to be untrue - item zero is OK."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bad filenames\n",
    "There were some files recovered that had unreadable filenames. First check that this is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_fname(path, fname):\n",
    "    if path[-1] != '/':\n",
    "        path = path + '/'\n",
    "    files = glob.glob('/media/programs/' + path + fname.replace('\\ufffd', '*'))\n",
    "    if len(files) == 1:\n",
    "        return files[0]\n",
    "    return '/media/programs/' + path + fname\n",
    "\n",
    "\n",
    "def check_for_file(item_row):\n",
    "    return os.path.isfile(get_fname(item_row.path, item_row.filename))    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path not found for 0\n"
     ]
    }
   ],
   "source": [
    "# sanity check on item zero\n",
    "item_zero['file found'] = item_zero.apply(check_for_file, axis=1)\n",
    "print(f'Path not found for {sum(item_zero[\"file found\"] == False)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path not found for 0\n"
     ]
    }
   ],
   "source": [
    "items['file found'] = items.apply(check_for_file, axis=1)\n",
    "print(f'Path not found for {sum(items[\"file found\"] == False)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duration of files\n",
    "The files on the disk did not have the length field filled in. As a sanity check it might be a good idea to check that all the files have the right duration. This section uses pydub to find the length of all files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_audio_length(row):\n",
    "    if not np.isnan(row.length):\n",
    "        return row.length\n",
    "    else:\n",
    "        audio = AudioSegment.from_file(get_fname(row.path, row.filename))\n",
    "        return audio.duration_seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "item_zero = item_zero.copy()\n",
    "item_zero['secs'] = item_zero.apply(determine_audio_length, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is going to take a long time to execute and the time appears to be correct anyway. We also need to factor in the unreadable filenames. Lets just do it for the files we need to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "items['secs'] = items.apply(determine_audio_length, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.drop(columns=['length'], inplace=True)\n",
    "items.rename(columns={ 'secs' : 'length' })\n",
    "items.to_csv(\"../../data/items_all.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0.1', 'Unnamed: 0', 'iso', 'language_name', 'track',\n",
      "       'location', 'year', 'path', 'filename', 'ID', 'item', 'title', 'start',\n",
      "       'duration', 'end', 'type', 'program', 'file found', 'length'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "items = pd.read_csv(\"../../data/items_all.csv\")\n",
    "\n",
    "print(items.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.rename(columns={ 'secs' : 'length' }, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.drop(columns=['Unnamed: 0', 'Unnamed: 0.1'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.to_csv(\"../../data/items_all.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time reconstruction\n",
    "As a starting point lets use the time reconstruction originally used. My initial code used two things to determine that a file was a compound file - a filename ending in A or B and when multiple items appear in the one file. Using the filename is a bit weak because GRN are not consistent. Using multiple items would appear to be more robust BUT there is a chance that filtered out items have left files with just one item. There might be some files in this category, but it is unlikely.\n",
    "\n",
    "For the voxGRN data we know that a diamond in the name means it is definitely a compound item.\n",
    "\n",
    "Lets see if we can identify compound items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compound records: 54890\n"
     ]
    }
   ],
   "source": [
    "items['compound'] = items.duplicated(subset=['path', 'filename'], keep=False)\n",
    "print(f'Compound records: {sum(items[\"compound\"])}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rules used originally included the following description:\n",
    "\n",
    "    Now there are two types of items - compound and single. We want the same method to access each. The solution is to create a start time and an end time for each.\n",
    "\n",
    "    The rules for creating this start and end times should be as follows:\n",
    "\n",
    "### Single Item Files\n",
    "    Item Start Time seems to not be related to the file. Is it the original location? Ignore it.\n",
    "    Assume the start time is the beginning of the file.\n",
    "\n",
    "| Scenario | End Time | Item Time | Action |\n",
    "| -------- | -------- | --------- | ------ |\n",
    "| 1.       | No       | No        | End = Length of file. |\n",
    "| 2.       | Yes      | No        | End = End Time. |\n",
    "| 3.       | No       | Yes       | End = Item Time.   |\n",
    "| 4.       | Yes      | Yes       | End = Item Time.  |\n",
    "\n",
    "    End must be checked to ensure it is less than file length.\n",
    "\n",
    "    For compound files (including files that appear multiple times in the data):\n",
    "\n",
    "| Scenario | Start Time | End Time | Item Time | Action |\n",
    "| -------- | ---------- | -------- | --------- | ------ |\n",
    "| 1.       | No         | No       | No        | Start = 0, End = Length of File |\n",
    "| 2.       | No         | No       | Yes       | Start = 0, End = Item Time |\n",
    "| 3.       | No         | Yes      | No        | Start = 0, End = End Time |\n",
    "| 4.       | No         | Yes      | Yes       | Start = max(0, End Time - Item Time), End = End Time |\n",
    "| 5.       | Yes        | No       | No        | Start = Start Time, End = Length of File |\n",
    "| 6.       | Yes        | No       | Yes       | Start = Start Time, End = Start + Item Time |\n",
    "| 7.       | Yes        | Yes      | No        | Start = Start Time, End = End Time |\n",
    "| 8.       | Yes        | Yes      | Yes       | Start = Start Time, End = End Time |\n",
    "\n",
    "    End must be check to ensure it is less than the length of the file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try some time functions\n",
    "import re\n",
    "\n",
    "def extract_seconds(_time):\n",
    "    if isinstance(_time, str):\n",
    "        m = re.search(r'([0-9]{1,2})\\:([0-9]{2})', _time)\n",
    "        if m:\n",
    "            min = float(m.group(1))\n",
    "            sec = float(m.group(2))\n",
    "            return min * 60.0 + sec\n",
    "    return 0.0\n",
    "\n",
    "def calculate_item_start_position(row):\n",
    "    if row['compound']:\n",
    "        if row['end'] and row['duration'] and not row['start']:\n",
    "            return max(0.0, extract_seconds(row['end']) - extract_seconds(row['duration']))\n",
    "        return extract_seconds(row['start'])\n",
    "    return 0.0\n",
    "    \n",
    "def calculate_item_end_position(row):\n",
    "    end_time = row.length\n",
    "    if row.compound:\n",
    "        if row.end:\n",
    "            end_time = extract_seconds(row.end)\n",
    "        elif row.duration:\n",
    "            end_time = extract_seconds(row.duration)\n",
    "            if row.start:\n",
    "                end_time += extract_seconds(row.start)\n",
    "\n",
    "    else:\n",
    "        if row.duration:\n",
    "            end_time = extract_seconds(row.duration)\n",
    "        elif row.end:\n",
    "            end_time = extract_seconds(row.end)\n",
    "    return min(row.length, end_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to apply these rules to the data and look at how they perform empirically. Cannot see any other way to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "items['_start'] = items.apply(calculate_item_start_position,axis=1)\n",
    "items['_end'] = items.apply(calculate_item_end_position,axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets see how well this did with the following groups:\n",
    "1. wav files with multiple items.\n",
    "2. mp3 files with multiple items.\n",
    "3. wav files with the old a|b that were not marked as compound.\n",
    "4. mp3 with a diamond and not marked compound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "items['wav'] = items.filename.str.upper().str.endswith('WAV') \n",
    "items['AB'] = items.filename.str.contains('[ACV]?[0-9]{5}[\\-\\=]?[ABab]\\.', regex=True)\n",
    "items['diamond'] = items.filename.str.contains(\"♦\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. wav files with multiple items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_multi_not_ab = items[items.wav & ~items.AB & items.compound].copy()\n",
    "wav_multi_not_ab.drop(columns=['wav', 'AB', 'diamond', 'file found'], inplace=True)\n",
    "wav_multi_ab = items[items.wav & items.AB & items.compound].copy()\n",
    "wav_multi_ab.drop(columns=['wav', 'AB', 'diamond', 'file found'], inplace=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the first file: 003350.wav It as 4 items at:\n",
    "1. 0 to 186     Actually does not start for 10 seconds. Ends at 200\n",
    "2. 191 to 375   Starts at 207 ends with music at 370-396\n",
    "3. 380 to 582   Starts 401 with music 596 with music to 608\n",
    "4. 587 to 790   Starts 611 to 825\n",
    "\n",
    "Now this file is a lot longer - about twice the size. What is in the rest of the file?\n",
    "\n",
    "There is an A and B side. It appears that both A and B are in the one wav. The start and end times appear to be relative to the tape side.\n",
    "\n",
    "How did we lose the B side items? Because we assume different tracks to be in different files we lost the B side. Humph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program items shape: (267681, 21)\n"
     ]
    }
   ],
   "source": [
    "grid_items = pd.read_csv(\"/prometheus/GRN/grid_program_items.csv\")\n",
    "print(f'Program items shape: {grid_items.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Programs/03/03350/C03350/PM/ 03350.wav\n",
      "Programs/03/03230/C03230/Copy_From_MP3_CM/ C03230A.wav\n"
     ]
    }
   ],
   "source": [
    "print(f'{wav_multi_not_ab.iloc[0].path} {wav_multi_not_ab.iloc[0].filename}')\n",
    "print(f'{wav_multi_ab.iloc[0].path} {wav_multi_ab.iloc[0].filename}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at a file with A or B in it: C03230A.wav:\n",
    "1. Item 1 0 to 405. Started at 0 and stopped 405\n",
    "2. Item 2 410 to 767 Started 410 and finished 767"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Multi files with diamonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_diamond = items[items.diamond & items.compound]\n",
    "single_diamond = items[items.diamond & ~items.compound]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vox_grn/Audio_MP3/10/10990 Huave de San Mateo del Mar Words of Life 002 NT Portions ♦ Instrumental 10990.mp3\n",
      "vox_grn/Audio_MP3/03/03130 Sadri Words of Life 001 Who is He ♦ What is a Christian ♦ Instrumental - Kului ♦ Power Ov 03130.mp3\n"
     ]
    }
   ],
   "source": [
    "print(f'{single_diamond.iloc[0].path} {single_diamond.iloc[0].filename}')\n",
    "print(f'{multi_diamond.iloc[0].path} {multi_diamond.iloc[0].filename}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The single diamond file is one item and an instrumental. The instrumental appears to be hidden at the end of the file. It ends at 1790 - when stated.\n",
    "The multi diamond:\n",
    "1. 0 to 235 actually goes 0 to 240\n",
    "2. 240 to 436 actually goes 246 to 450\n",
    "3. Was an instrumental that has been skipped. Ends at 480. \n",
    "4. 469 to 660 actually goes 481 to 675\n",
    "5. 665 to 868 actually goes 680 \n",
    "\n",
    "## Conclusion\n",
    "The value in using items is to add the item type meta data field. This would seem to be a lost cause as the labelled information is often incorrect. This is compounded by the time stamps being erroneous.\n",
    "\n",
    "If we wind back and only use the files is it correct to assume:\n",
    "1. Each file has only one language.\n",
    "2. Our VAD can correctly discern music from voice.\n",
    "\n",
    "Furthermore, for single item files can we discard instrumentals/announcements reliably?\n",
    "\n",
    "These assumptions will be tested in FileInvestigation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

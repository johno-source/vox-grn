{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I do not understand why in this example they classify on the file - not the audio stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85bc50812804b6592eff824f081977e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/19.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset superb_demo/er to /home/jovyan/.cache/huggingface/datasets/anton-l___superb_demo/er/1.9.0/77d23894ff429329a7fe80f9007cabb0deec321316f8dda1a1e9d10ffa089d08...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2d3a0aa373444aba908bb83dd21373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.21M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b193e5fea8114448a047448510b16148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating session1 split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset superb_demo downloaded and prepared to /home/jovyan/.cache/huggingface/datasets/anton-l___superb_demo/er/1.9.0/77d23894ff429329a7fe80f9007cabb0deec321316f8dda1a1e9d10ffa089d08. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25454eb53f20442a8c37c178490e8c8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5722aa4c92db415fbf857e7906869152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd5dd06b2d64a4d95adec52b8a892ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading preprocessor_config.json:   0%|          | 0.00/212 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "\n",
    "dataset = load_dataset(\"anton-l/superb_demo\", \"er\", split=\"session1\")\n",
    "\n",
    "classifier = pipeline(\"audio-classification\", model=\"superb/hubert-large-superb-er\")\n",
    "labels = classifier(dataset[0][\"file\"], top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.cache/huggingface/datasets/downloads/extracted/78e6da90361e53b909a57c3b6dc0334cd09f6bc67691afb514a961f5df6e9bdf/Session1/sentences/wav/Ses01F_impro03/Ses01F_impro03_F013.wav\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0]['file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.9982258677482605, 'label': 'hap'}, {'score': 0.001702160807326436, 'label': 'sad'}, {'score': 4.696955147664994e-05, 'label': 'neu'}, {'score': 2.500531445548404e-05, 'label': 'ang'}]\n"
     ]
    }
   ],
   "source": [
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'path': '/home/jovyan/.cache/huggingface/datasets/downloads/extracted/78e6da90361e53b909a57c3b6dc0334cd09f6bc67691afb514a961f5df6e9bdf/Session1/sentences/wav/Ses01F_impro03/Ses01F_impro03_F013.wav', 'array': array([ 0.01025391,  0.00134277, -0.0039978 , ..., -0.00027466,\n",
      "       -0.00231934, -0.00259399], dtype=float32), 'sampling_rate': 16000}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0]['audio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why in this example do they use librosa to load the file into speech - why not use audio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset superb_demo (/home/jovyan/.cache/huggingface/datasets/anton-l___superb_demo/er/1.9.0/77d23894ff429329a7fe80f9007cabb0deec321316f8dda1a1e9d10ffa089d08)\n",
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/anton-l___superb_demo/er/1.9.0/77d23894ff429329a7fe80f9007cabb0deec321316f8dda1a1e9d10ffa089d08/cache-374cee6acfc77828.arrow\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import librosa\n",
    "from datasets import load_dataset\n",
    "from transformers import HubertForSequenceClassification, Wav2Vec2FeatureExtractor\n",
    "\n",
    "def map_to_array(example):\n",
    "    speech, _ = librosa.load(example[\"file\"], sr=16000, mono=True)\n",
    "    example[\"speech\"] = speech\n",
    "    return example\n",
    "\n",
    "# load a demo dataset and read audio files\n",
    "dataset = load_dataset(\"anton-l/superb_demo\", \"er\", split=\"session1\")\n",
    "dataset = dataset.map(map_to_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = HubertForSequenceClassification.from_pretrained(\"superb/hubert-large-superb-er\")\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"superb/hubert-large-superb-er\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compute attention masks and normalize the waveform if needed\n",
    "inputs = feature_extractor(dataset[:2][\"speech\"], sampling_rate=16000, padding=True, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[ 0.01025391  0.00134277 -0.0039978  -0.00628662]\n",
      "2\n",
      "[0.01025390625, 0.0013427734375, -0.003997802734375, -0.00628662109375]\n",
      "{'path': '/home/jovyan/.cache/huggingface/datasets/downloads/extracted/78e6da90361e53b909a57c3b6dc0334cd09f6bc67691afb514a961f5df6e9bdf/Session1/sentences/wav/Ses01F_impro03/Ses01F_impro03_F013.wav', 'array': array([ 0.01025391,  0.00134277, -0.0039978 , ..., -0.00027466,\n",
      "       -0.00231934, -0.00259399], dtype=float32), 'sampling_rate': 16000}\n"
     ]
    }
   ],
   "source": [
    "print(type(dataset[:2]['speech'][0]))\n",
    "print(dataset[0]['audio']['array'][:4])\n",
    "print(len(dataset[:2]['audio']))\n",
    "print(dataset[:2]['speech'][0][:4])\n",
    "print(dataset[:2]['audio'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_input = feature_extractor([audio['array'] for audio in dataset[:2]['audio']], sampling_rate=16000, padding=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# logits = model(**inputs).logits\n",
    "logits = model(**alt_input).logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "labels = [model.config.id2label[_id] for _id in predicted_ids.tolist()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
